name: Debug Data Inspector
description: Downloads and inspects data file to understand its structure
inputs:
  - name: cdn_url
    type: String
    description: CDN URL to download data file (use %24%24 for $$)
outputs:
  - name: raw_data_file
    type: Dataset
    description: Downloaded raw data file

implementation:
  container:
    image: python:3.9
    command:
      - sh
      - -c
      - |
        set -e
        python3 -m pip install --quiet requests
        python3 -c "
        import sys, os, requests, urllib.parse, json
        
        print('Number of arguments:', len(sys.argv))
        print('Arguments:', sys.argv)
        
        cdn_url = sys.argv[1]
        raw_data_path = sys.argv[2]
        
        print('=== STARTING DATA INSPECTION ===')
        
        decoded_url = urllib.parse.unquote(cdn_url)
        print(f'Fetching data from: {decoded_url}')
        
        response = requests.get(decoded_url)
        response.raise_for_status()
        content = response.text
        
        print(f'=== DOWNLOADED DATA SIZE: {len(content)} characters ===')
        
        # Print first 2000 characters to see structure
        print('=== FIRST 2000 CHARACTERS ===')
        print(content[:2000])
        print('...')
        
        print('=== ANALYZING DATA STRUCTURE ===')
        lines = content.splitlines()
        
        # Find all sections and their content
        sections = {}
        current_section = None
        current_content = []
        
        for i, line in enumerate(lines):
            line = line.strip()
            if not line:
                continue
                
            # Check if this is a section header
            if line.endswith('Data:'):
                # Save previous section if exists
                if current_section:
                    sections[current_section] = current_content
                    print(f'Section {current_section}: {len(current_content)} lines')
                
                current_section = line.replace('Data:', '').strip()
                current_content = []
                print(f'Found section: {current_section} at line {i}')
                continue
                
            if current_section:
                current_content.append(line)
        
        # Save the last section
        if current_section:
            sections[current_section] = current_content
            print(f'Section {current_section}: {len(current_content)} lines')
        
        print('=== SECTION SUMMARY ===')
        for section_name, section_lines in sections.items():
            print(f'{section_name}: {len(section_lines)} lines')
            if section_lines:
                # Show first few lines of each section
                print(f'  First 3 lines:')
                for j, sl in enumerate(section_lines[:3]):
                    print(f'    {j+1}: {sl[:100]}...' if len(sl) > 100 else f'    {j+1}: {sl}')
                print('  ...')
        
        # Try to find JSON data in each section
        print('=== LOOKING FOR JSON DATA ===')
        for section_name, section_lines in sections.items():
            print(f'Checking section: {section_name}')
            
            # Look for JSON array pattern
            json_found = False
            for i, line in enumerate(section_lines):
                if line.strip() == '[':
                    print(f'  Found JSON array start at line {i}')
                    # Try to find the closing bracket
                    for j in range(i, min(i+10, len(section_lines))):
                        if section_lines[j].strip() == ']':
                            print(f'  Found JSON array end at line {j}')
                            json_found = True
                            # Try to parse the JSON
                            json_str = ' '.join(section_lines[i:j+1])
                            try:
                                data = json.loads(json_str)
                                print(f'  SUCCESS: Parsed {len(data)} JSON objects')
                                break
                            except json.JSONDecodeError as e:
                                print(f'  FAILED: JSON parse error: {e}')
                                print(f'  JSON string sample: {json_str[:200]}...')
                            break
                    if json_found:
                        break
            
            if not json_found:
                print(f'  No JSON array found in this section')
        
        print('=== SAVING RAW DATA ===')
        os.makedirs(os.path.dirname(raw_data_path) or '.', exist_ok=True)
        with open(raw_data_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print('=== INSPECTION COMPLETE ===')
        print(f'Raw data saved to: {raw_data_path}')
        " "$0" "$1" "$2"
    args:
      - {inputValue: cdn_url}
      - {outputPath: raw_data_file}
