name: F DQN RLAF Loop CNN
description: Triggers the DQN RLAF pipeline in a loop to optimize CNN model hyperparameters, controlled by a pierce_or_not flag.
inputs:
  - {name: trained_model, type: Model}
  - {name: init_metrics, type: Metrics}
  - {name: data_path, type: Dataset}
  - {name: config, type: String}
  - {name: domain, type: String}
  - {name: schema_id, type: String}
  - {name: model_id, type: String}
  - {name: dqn_pipeline_id, type: String}
  - {name: pipeline_domain, type: String}
  - {name: dqn_experiment_id, type: String}
  - {name: access_token, type: string}
  - {name: tasks, type: Dataset}
outputs:
  - {name: rlaf_output, type: Dataset}
  - {name: retrained_model, type: Model}

implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v19
    command:
      - sh
      - -c
      - |
        python3 -m pip install --quiet requests || \
        python3 -m pip install --quiet requests --user
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import torch
        import os
        import json
        import argparse
        import requests
        import pickle
        import time
        import numpy as np
        from typing import Dict, List, Any
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry
        from torch.utils.data import DataLoader
        import torch.nn as nn
        import torch.optim as optim
        from nesy_factory.CNNs.factory import CNNFactory

        # API Helper Functions
        def get_retry_session():
            retry_strategy = Retry(
                total=5,
                status_forcelist=[500, 502, 503, 504],
                backoff_factor=1
            )
            adapter = HTTPAdapter(max_retries=retry_strategy)
            session = requests.Session()
            session.mount("https://", adapter)
            session.mount("http://", adapter)
            return session

        def trigger_pipeline(config, pipeline_domain, dqn_params=None):
            try:
                http = get_retry_session()
                url = f"{pipeline_domain}/bob-service-test/v1.0/pipeline/trigger/ml?pipelineId={config['pipeline_id']}"
                pipeline_params = {"param_json": json.dumps(dqn_params)} if dqn_params else {}
                payload = json.dumps({
                    "pipelineType": "ML", 
                    "containerResources": {}, 
                    "experimentId": config['experiment_id'],
                    "enableCaching": True, 
                    "parameters": pipeline_params, 
                    "version": 1
                })
                headers = {
                    'accept': 'application/json', 
                    'Authorization': f"Bearer {config['access_token']}",
                    'Content-Type': 'application/json'
                }
                print(f"Triggering DQN pipeline: {url}")
                response = http.post(url, headers=headers, data=payload, timeout=30)
                response.raise_for_status()
                result = response.json()
                print(f"DQN pipeline triggered successfully. Run ID: {result['runId']}")
                return result['runId']
            except Exception as e:
                print(f"Failed to trigger DQN pipeline: {e}")
                raise

        def get_pipeline_status(config, pipeline_domain):
            try:
                http = get_retry_session()
                url = f"{pipeline_domain}/bob-service-test/v1.0/pipeline/{config['pipeline_id']}/status/ml/{config['run_id']}"
                headers = {
                    'accept': 'application/json', 
                    'Authorization': f"Bearer {config['access_token']}"
                }
                response = http.get(url, headers=headers, timeout=30)
                response.raise_for_status()
                pipeline_status = response.json()
                latest_state = pipeline_status['run_details']['state_history'][-1]
                print(f"DQN pipeline status: {latest_state['state']}")
                return latest_state['state']
            except Exception as e:
                print(f"Failed to get pipeline status: {e}")
                return 'UNKNOWN'

        def get_instance(access_token, domain, schema_id, model_id):
            http = get_retry_session()
            url = f"{domain}/pi-entity-instances-service/v3.0/schemas/{schema_id}/instances/list"
            headers = {
                "Authorization": f"Bearer {access_token}", 
                "Content-Type": "application/json"
            }
            payload = {
                "dbType": "TIDB", 
                "ownedOnly": True, 
                "filter": {"model_id": model_id}
            }
            response = http.post(url, headers=headers, json=payload, timeout=30)
            response.raise_for_status()
            data = response.json()
            if not data['content']:
                raise ValueError(f"No instance found for model_id: {model_id}")
            return data['content'][0]

        def update_instance_field(access_token, domain, schema_id, model_id, field, value):
            http = get_retry_session()
            url = f"{domain}/pi-entity-instances-service/v2.0/schemas/{schema_id}/instances"
            headers = {
                "Authorization": f"Bearer {access_token}", 
                "Content-Type": "application/json"
            }
            payload = {
                "dbType": "TIDB",
                "conditionalFilter": {
                    "conditions": [{
                        "field": "model_id", 
                        "operator": "EQUAL", 
                        "value": model_id
                    }]
                },
                "partialUpdateRequests": [{
                    "patch": [{
                        "operation": "REPLACE", 
                        "path": f"{field}", 
                        "value": value
                    }]
                }]
            }
            response = http.patch(url, headers=headers, data=json.dumps(payload), timeout=30)
            response.raise_for_status()

        # CNN Continual Learning Trainer
        class CNNContinualTrainer:
            def __init__(self, config: Dict[str, Any]):
                self.config = config
                self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
                
            def train_continual_cnn(self, tasks: List[Dict], model, strategies: List[str] = ['naive']) -> Dict[str, Any]:
                results = {}
                for strategy_name in strategies:
                    print(f'Training CNN with {strategy_name.upper()} strategy')
                    strategy_results = self._train_single_strategy(tasks, strategy_name, model)
                    results[strategy_name] = strategy_results
                return results
            
            def _train_single_strategy(self, tasks: List[Dict], strategy_name: str, model) -> Dict[str, Any]:
                task_metrics = []
                all_task_performance = []
                previous_task_data = []
                
                model.to(self.device)
                
                for task_idx, task_data in enumerate(tasks):
                    print(f"Learning Task {task_idx + 1}")
                    
                    # Apply strategy-specific training
                    if strategy_name == 'naive':
                        training_loader = task_data['train_loader']
                    elif strategy_name == 'replay' and previous_task_data:
                        training_loader = self._create_replay_loader(task_data, previous_task_data)
                    else:
                        training_loader = task_data['train_loader']
                    
                    # Train CNN on current task
                    current_metrics = self._train_cnn_on_task(model, training_loader, task_data['test_loader'])
                    task_metrics.append(current_metrics)
                    
                    # Evaluate on all tasks seen so far
                    task_performance = []
                    for eval_task_idx in range(task_idx + 1):
                        eval_metrics = self._evaluate_cnn_on_task(model, tasks[eval_task_idx]['test_loader'])
                        task_performance.append({
                            'task_id': eval_task_idx,
                            'accuracy': eval_metrics['accuracy'],
                            'loss': eval_metrics['loss']
                        })
                    
                    all_task_performance.append(task_performance)
                    
                    if strategy_name == 'replay':
                        previous_task_data.append(task_data)
                        if len(previous_task_data) > 2:
                            previous_task_data = previous_task_data[-2:]
                
                # Calculate continual learning metrics
                cl_metrics = self._calculate_continual_metrics(all_task_performance)
                
                # Final evaluation on all tasks
                final_eval_metrics = []
                for i in range(len(tasks)):
                    task_eval = self._evaluate_cnn_on_task(model, tasks[i]['test_loader'])
                    final_eval_metrics.append(task_eval)
                
                avg_metrics = {}
                if final_eval_metrics:
                    for key in final_eval_metrics[0]:
                        avg_metrics[key] = np.mean([m[key] for m in final_eval_metrics if key in m])

                return {
                    'strategy': strategy_name,
                    'task_metrics': task_metrics,
                    'all_task_performance': all_task_performance,
                    'continual_metrics': cl_metrics,
                    'final_model': model,
                    'average_eval_metrics': avg_metrics
                }
            
            def _train_cnn_on_task(self, model, train_loader, test_loader) -> Dict[str, float]:
                model.train()
                model.to(self.device)
                
                # Get training parameters from config
                training_config = self.config.get('training', {})
                optimizer_config = training_config.get('optimizer', {})
                
                learning_rate = optimizer_config.get('learning_rate', 0.001)
                weight_decay = optimizer_config.get('weight_decay', 0.01)
                epochs = training_config.get('epochs', 5)  # Reduced for faster iteration
                
                optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)
                criterion = nn.CrossEntropyLoss()
                
                for epoch in range(epochs):
                    total_loss = 0
                    correct = 0
                    total = 0
                    
                    for data, targets in train_loader:
                        data, targets = data.to(self.device), targets.to(self.device)
                        optimizer.zero_grad()
                        outputs = model(data)
                        loss = criterion(outputs, targets)
                        loss.backward()
                        optimizer.step()
                        
                        total_loss += loss.item()
                        _, predicted = outputs.max(1)
                        total += targets.size(0)
                        correct += predicted.eq(targets).sum().item()
                
                return self._evaluate_cnn_on_task(model, test_loader)
            
            def _evaluate_cnn_on_task(self, model, test_loader) -> Dict[str, float]:
                model.eval()
                model.to(self.device)
                
                criterion = nn.CrossEntropyLoss()
                total_loss = 0
                correct = 0
                total = 0
                
                with torch.no_grad():
                    for data, targets in test_loader:
                        data, targets = data.to(self.device), targets.to(self.device)
                        outputs = model(data)
                        loss = criterion(outputs, targets)
                        
                        total_loss += loss.item()
                        _, predicted = outputs.max(1)
                        total += targets.size(0)
                        correct += predicted.eq(targets).sum().item()
                
                accuracy = 100. * correct / total if total > 0 else 0.0
                avg_loss = total_loss / len(test_loader) if len(test_loader) > 0 else 0.0
                
                return {
                    'accuracy': accuracy,
                    'loss': avg_loss,
                    'correct': correct,
                    'total': total
                }
            
            def _create_replay_loader(self, current_task: Dict, previous_tasks: List[Dict]) -> DataLoader:
                from torch.utils.data import TensorDataset
                
                replay_ratio = 0.2
                current_loader = current_task['train_loader']
                current_size = len(current_loader.dataset)
                replay_size = int(current_size * replay_ratio / (1 - replay_ratio))
                
                replay_data = []
                replay_labels = []
                
                for prev_task in previous_tasks:
                    prev_loader = prev_task['train_loader']
                    prev_dataset = prev_loader.dataset
                    if len(prev_dataset) > 0:
                        sample_size = min(replay_size // len(previous_tasks), len(prev_dataset))
                        indices = torch.randperm(len(prev_dataset))[:sample_size]
                        for idx in indices:
                            data, label = prev_dataset[idx]
                            replay_data.append(data)
                            replay_labels.append(label)
                
                current_data = []
                current_labels = []
                for data, label in current_loader.dataset:
                    current_data.append(data)
                    current_labels.append(label)
                
                if replay_data:
                    combined_data = torch.cat([torch.stack(current_data), torch.stack(replay_data)])
                    combined_labels = torch.cat([torch.tensor(current_labels), torch.tensor(replay_labels)])
                else:
                    combined_data = torch.stack(current_data)
                    combined_labels = torch.tensor(current_labels)
                
                combined_dataset = TensorDataset(combined_data, combined_labels)
                return DataLoader(combined_dataset, batch_size=current_loader.batch_size, shuffle=True)
            
            def _calculate_continual_metrics(self, all_task_performance: List[List[Dict]]) -> Dict[str, float]:
                final_performance = all_task_performance[-1]
                average_accuracy = np.mean([task['accuracy'] for task in final_performance])
                average_loss = np.mean([task['loss'] for task in final_performance])
                
                return {
                    'average_accuracy': average_accuracy,
                    'average_loss': average_loss,
                    'num_tasks': len(all_task_performance)
                }

        # CNN Retraining Logic
        def cnn_retraining(action, model_path, data_path, config_str, tasks_path, output_model_path, previous_metrics, dqn_params):
            print("Starting CNN retraining...")
            
            # Load configuration
            config = json.loads(config_str)
            
            # Load tasks
            with open(tasks_path, "rb") as f:
                tasks = pickle.load(f)
            
            # Update config with DQN action parameters
            model_config = config.get('model', {})
            training_config = config.get('training', {})
            
            # Apply action parameters to model and training config
            for param_key, param_value in action.items():
                if 'learning_rate' in param_key:
                    training_config['optimizer']['learning_rate'] = float(param_value)
                elif 'batch_size' in param_key:
                    training_config['batch_size'] = int(param_value)
                elif 'epochs' in param_key:
                    training_config['epochs'] = int(param_value)
                elif 'architecture' in param_key:
                    model_config['architecture'] = param_value
                elif 'variant' in param_key:
                    model_config['variant'] = param_value
            
            # Create CNN model using CNNFactory
            model = CNNFactory.create_model(model_config['architecture'], model_config)
            
            # Load pre-trained weights
            model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))
            
            # Train model with continual learning
            trainer = CNNContinualTrainer(config)
            results = trainer.train_continual_cnn(tasks=tasks, strategies=['naive'], model=model)
            
            average_eval_metrics = results['naive']['average_eval_metrics']
            
            # Calculate improvement score
            improvement_score = 0
            for param in dqn_params:
                key = param['key']
                sign = 1 if param['sign'] == '+' else -1
                if key in average_eval_metrics and key in previous_metrics:
                    improvement = (average_eval_metrics[key] - previous_metrics[key]) * sign
                    improvement_score += improvement * param.get('mul', 1.0)

            print(f"Improvement score: {improvement_score:.4f}")
            
            # Save model
            os.makedirs(os.path.dirname(output_model_path), exist_ok=True)
            
            if improvement_score > 0:
                print("Metrics improved - saving retrained model")
                final_model = results['naive']['final_model']
                torch.save(final_model.state_dict(), output_model_path)
            else:
                print("No improvement - saving original model")
                torch.save(model.state_dict(), output_model_path)

            return {"metrics": average_eval_metrics, "model_path": output_model_path}

        def trigger_and_wait_for_dqn_pipeline(config, pipeline_domain, dqn_params):
            try:
                run_id = trigger_pipeline(config, pipeline_domain, dqn_params)
                config["run_id"] = run_id
                
                max_wait_time = 1800  # 30 minutes max
                start_time = time.time()
                
                while time.time() - start_time < max_wait_time:
                    status = get_pipeline_status(config, pipeline_domain)
                    
                    if status == 'SUCCEEDED':
                        print("DQN pipeline completed successfully")
                        return True
                    elif status in ['FAILED', 'ERROR', 'CANCELLED']:
                        print(f"DQN pipeline failed with status: {status}")
                        return False
                    
                    time.sleep(30)  # Check every 30 seconds
                
                print("DQN pipeline timeout")
                return False
                
            except Exception as e:
                print(f"Error in DQN pipeline execution: {e}")
                return False

        # Main execution
        def main():
            parser = argparse.ArgumentParser()
            parser.add_argument('--trained_model', type=str, required=True)
            parser.add_argument('--init_metrics', type=str, required=True)
            parser.add_argument('--rlaf_output', type=str, required=True)
            parser.add_argument('--data_path', type=str, required=True)
            parser.add_argument('--config', type=str, required=True)
            parser.add_argument('--domain', type=str, required=True)
            parser.add_argument('--schema_id', type=str, required=True)
            parser.add_argument('--model_id', type=str, required=True)
            parser.add_argument('--dqn_pipeline_id', type=str, required=True)
            parser.add_argument('--dqn_experiment_id', type=str, required=True)
            parser.add_argument('--access_token', type=str, required=True)
            parser.add_argument('--tasks', type=str, required=True)
            parser.add_argument('--pipeline_domain', type=str, required=True)
            parser.add_argument('--retrained_model', type=str, required=True)
            args = parser.parse_args()

            print("Starting CNN RLAF Loop...")
            
            # Load access token
            with open(args.access_token, 'r') as f:
                access_token = f.read().strip()
            
            # Load initial metrics
            with open(args.init_metrics, 'r') as f:
                current_metrics_data = json.load(f)
            
            # Extract numeric metrics
            current_metrics = {}
            if isinstance(current_metrics_data, dict):
                for key, value in current_metrics_data.items():
                    if isinstance(value, (int, float)):
                        current_metrics[key] = float(value)
            else:
                current_metrics = {'accuracy': 50.0, 'loss': 1.0}
            
            print(f"Loaded metrics: {current_metrics}")
            
            # Create default action for when DQN fails
            default_action = {
                'learning_rate': 0.001,
                'batch_size': 32,
                'epochs': 5
            }
            
            for i in range(2):  # RLAF loop iterations
                print(f"=== CNN RLAF Iteration {i+1} ===")
                
                # Prepare metrics for DQN
                cleaned_metrics = {}
                dqn_params = []
                for key, value in current_metrics.items():
                    cleaned_metrics[key] = float(value)
                    if any(term in key.lower() for term in ["accuracy", "f1", "precision", "recall"]):
                        sign = "+"
                    else:
                        sign = "-"
                    dqn_params.append({"key": key, "sign": sign, "mul": 1.0})
                
                print(f"DQN parameters: {json.dumps(dqn_params, indent=2)}")
                
                # Update database with current state
                try:
                    instance = get_instance(access_token, args.domain, args.schema_id, args.model_id)
                    
                    if instance.get('pierce2rlaf'):
                        latest_pierce2rlaf = instance['pierce2rlaf'][-1]
                        previous_state = latest_pierce2rlaf['current_state']
                    else:
                        previous_state = {key: 0.0 for key in cleaned_metrics.keys()}
                    
                    new_pierce2rlaf_entry = {
                        "action_id": -1, 
                        "previous_state": previous_state,
                        "current_state": cleaned_metrics, 
                        "episode": i, 
                        "timestamp": int(time.time())
                    }
                    
                    pierce2rlaf_history = instance.get("pierce2rlaf", [])
                    pierce2rlaf_history.append(new_pierce2rlaf_entry)
                    update_instance_field(access_token, args.domain, args.schema_id, args.model_id, 
                                        "pierce2rlaf", pierce2rlaf_history)
                    
                    print("Updated database state")
                    
                except Exception as e:
                    print(f"Warning: Could not update database: {e}")
                
                # Try to trigger DQN pipeline
                dqn_success = False
                action_to_use = default_action
                
                try:
                    dqn_config = {
                        "pipeline_id": args.dqn_pipeline_id, 
                        "experiment_id": args.dqn_experiment_id, 
                        "access_token": access_token
                    }
                    dqn_success = trigger_and_wait_for_dqn_pipeline(dqn_config, args.pipeline_domain, dqn_params)
                    
                    if dqn_success:
                        # Get DQN recommendation
                        updated_instance = get_instance(access_token, args.domain, args.schema_id, args.model_id)
                        
                        if updated_instance.get('rlaf2pierce'):
                            latest_rlaf2pierce = updated_instance['rlaf2pierce'][-1]
                            
                            if latest_rlaf2pierce.get("pierce_or_not", True):
                                rlaf_actions = updated_instance.get('rlaf_actions', {}).get('actions', [])
                                action_id = latest_rlaf2pierce['action_id']
                                action_details = next((a for a in rlaf_actions if a["id"] == action_id), None)
                                
                                if action_details:
                                    action_to_use = action_details['params']
                                    print(f"Using DQN action: {action_to_use}")
                                else:
                                    print("DQN action not found, using default")
                            else:
                                print("pierce_or_not is false. Stopping RLAF loop.")
                                break
                        else:
                            print("No DQN recommendations, using default action")
                    else:
                        print("DQN pipeline failed, using default action")
                        
                except Exception as e:
                    print(f"DQN pipeline error: {e}, using default action")
                
                # Always retrain model (with DQN action or default)
                print(f"Retraining with action: {action_to_use}")
                retraining_results = cnn_retraining(
                    action_to_use, 
                    args.trained_model, 
                    args.data_path, 
                    args.config, 
                    args.tasks,
                    args.retrained_model, 
                    previous_state, 
                    dqn_params
                )
                
                current_metrics = retraining_results["metrics"]
                print(f"Updated metrics after retraining: {current_metrics}")
            
            # Save final results
            os.makedirs(os.path.dirname(args.rlaf_output), exist_ok=True)
            final_output = {
                "final_metrics": current_metrics,
                "model_type": "CNN_image_classifier",
                "iterations_completed": i + 1,
                "timestamp": time.time()
            }
            
            with open(args.rlaf_output, 'w') as f:
                json.dump(final_output, f, indent=2)
            
            print(f"CNN RLAF loop completed successfully. Results saved to: {args.rlaf_output}")

        if __name__ == '__main__':
            main()
    args:
      - --trained_model
      - {inputPath: trained_model}
      - --init_metrics
      - {inputPath: init_metrics}
      - --rlaf_output
      - {outputPath: rlaf_output}
      - --data_path
      - {inputPath: data_path}
      - --config
      - {inputValue: config}
      - --domain
      - {inputValue: domain}
      - --schema_id
      - {inputValue: schema_id}
      - --model_id
      - {inputValue: model_id}
      - --dqn_pipeline_id
      - {inputValue: dqn_pipeline_id}
      - --dqn_experiment_id
      - {inputValue: dqn_experiment_id}
      - --access_token
      - {inputPath: access_token}
      - --tasks
      - {inputPath: tasks}
      - --pipeline_domain
      - {inputValue: pipeline_domain}
      - --retrained_model
      - {outputPath: retrained_model}
