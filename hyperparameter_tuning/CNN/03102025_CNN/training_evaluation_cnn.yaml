name: CNN Training & Evaluation
description: Universal CNN training and evaluation

inputs:
  - name: data_path
    type: String
    description: Preprocessed data path from preprocessing brick
    
  - name: num_classes
    type: Integer
    description: Number of classes
    
  - name: input_shape
    type: String
    description: Input shape as "channels,height,width"
    
  - name: model_config
    type: String
    description: Complete model configuration as JSON string
    default: "{\"layers\": [{\"type\": \"conv\", \"out_channels\": 32, \"kernel_size\": 3, \"padding\": 1, \"batch_norm\": true, \"dropout\": 0.1}, {\"type\": \"maxpool\", \"kernel_size\": 2}, {\"type\": \"conv\", \"out_channels\": 64, \"kernel_size\": 3, \"padding\": 1, \"batch_norm\": true, \"dropout\": 0.2}, {\"type\": \"maxpool\", \"kernel_size\": 2}, {\"type\": \"conv\", \"out_channels\": 128, \"kernel_size\": 3, \"padding\": 1, \"batch_norm\": true, \"dropout\": 0.3}, {\"type\": \"maxpool\", \"kernel_size\": 2}], \"fc_layers\": [256, 128], \"fc_dropout\": 0.5, \"optimizer\": {\"type\": \"adam\", \"lr\": 0.001}, \"epochs\": 10, \"batch_size\": 64, \"dataset\": \"mnist\", \"validation_split\": 0.2, \"task_type\": \"classification\"}"

outputs:
  - name: test_accuracy
    type: Float
    description: Final test accuracy
    
  - name: test_f1_score
    type: Float
    description: Final test F1 score
    
  - name: best_val_accuracy
    type: Float
    description: Best validation accuracy
    
  - name: model_path
    type: string
    description: Path to saved model

implementation:
  container:
    image: nikhilv215/nesy-factory:v18
    command:
      - python3
      - -u
      - -c
      - |
        import os
        import json
        import pickle
        from pathlib import Path
        import torch
        import torch.nn as nn
        import torch.optim as optim
        from sklearn.metrics import accuracy_score, f1_score
        import argparse
        
        # Argument parsing
        parser = argparse.ArgumentParser()
        parser.add_argument("--data_path", type=str, required=True)
        parser.add_argument("--num_classes", type=int, required=True)
        parser.add_argument("--input_shape", type=str, required=True)
        parser.add_argument("--model_config", type=str, required=True)
        parser.add_argument("--test_accuracy", type=str, required=True)
        parser.add_argument("--test_f1_score", type=str, required=True)
        parser.add_argument("--best_val_accuracy", type=str, required=True)
        parser.add_argument("--model_path", type=str, required=True)
        args = parser.parse_args()
        
        # Parse configurations
        config = json.loads(args.model_config)
        input_shape = tuple(map(int, args.input_shape.split(',')))
        
        print("=== CNN TRAINING & EVALUATION ===")
        print(f"Data path: {args.data_path}")
        print(f"Number of classes: {args.num_classes}")
        print(f"Input shape: {input_shape}")
        print(f"Model config: {config}")
        
        class DynamicCNN(nn.Module):
            def __init__(self, config, input_shape, num_classes):
                super(DynamicCNN, self).__init__()
                
                self.config = config
                self.input_shape = input_shape
                self.num_classes = num_classes
                
                conv_layers = []
                in_channels = input_shape[0]
                
                for layer_cfg in config['layers']:
                    if layer_cfg['type'] == 'conv':
                        conv_layers.append(nn.Conv2d(
                            in_channels,
                            layer_cfg['out_channels'],
                            kernel_size=layer_cfg['kernel_size'],
                            stride=layer_cfg.get('stride', 1),
                            padding=layer_cfg.get('padding', 0)
                        ))
                        
                        if layer_cfg.get('batch_norm', False):
                            conv_layers.append(nn.BatchNorm2d(layer_cfg['out_channels']))
                        
                        conv_layers.append(nn.ReLU())
                        
                        if layer_cfg.get('dropout', 0) > 0:
                            conv_layers.append(nn.Dropout2d(layer_cfg['dropout']))
                        
                        in_channels = layer_cfg['out_channels']
                        
                    elif layer_cfg['type'] == 'maxpool':
                        conv_layers.append(nn.MaxPool2d(
                            kernel_size=layer_cfg['kernel_size'],
                            stride=layer_cfg.get('stride', layer_cfg['kernel_size'])
                        ))
                
                self.conv = nn.Sequential(*conv_layers)
                self.adaptive_pool = nn.AdaptiveAvgPool2d((4, 4))
                self.flatten = nn.Flatten()
                
                # Calculate flattened size
                with torch.no_grad():
                    x = torch.zeros(1, *input_shape)
                    x = self.conv(x)
                    x = self.adaptive_pool(x)
                    flattened_size = x.view(1, -1).size(1)
                
                fc_layers = []
                in_features = flattened_size
                
                for fc_units in config.get('fc_layers', [128]):
                    fc_layers.append(nn.Linear(in_features, fc_units))
                    fc_layers.append(nn.ReLU())
                    fc_layers.append(nn.Dropout(config.get('fc_dropout', 0.5)))
                    in_features = fc_units
                
                fc_layers.append(nn.Linear(in_features, num_classes))
                self.fc = nn.Sequential(*fc_layers)
            
            def forward(self, x):
                x = self.conv(x)
                x = self.adaptive_pool(x)
                x = self.flatten(x)
                x = self.fc(x)
                return x

        def load_data_loaders(data_path):
            """Load data loaders from preprocessed directory"""
            train_loader_path = os.path.join(data_path, 'train_loader.pth')
            val_loader_path = os.path.join(data_path, 'val_loader.pth')
            test_loader_path = os.path.join(data_path, 'test_loader.pth')
            
            if not os.path.exists(train_loader_path):
                raise FileNotFoundError(f"Train loader not found: {train_loader_path}")
            if not os.path.exists(test_loader_path):
                raise FileNotFoundError(f"Test loader not found: {test_loader_path}")
            
            train_loader = torch.load(train_loader_path)
            test_loader = torch.load(test_loader_path)
            
            # Load validation loader if exists, else use test loader
            if os.path.exists(val_loader_path):
                val_loader = torch.load(val_loader_path)
            else:
                print("Warning: Validation loader not found, using test loader for validation")
                val_loader = test_loader
            
            print(f"Loaded data loaders: train={len(train_loader)}, val={len(val_loader)}, test={len(test_loader)}")
            return train_loader, val_loader, test_loader

        def train_model(model, train_loader, val_loader, config, device):
            """Train the model"""
            criterion = nn.CrossEntropyLoss()
            
            optim_config = config['optimizer']
            if optim_config['type'] == 'adam':
                optimizer = optim.Adam(model.parameters(), lr=optim_config['lr'])
            elif optim_config['type'] == 'sgd':
                optimizer = optim.SGD(model.parameters(), lr=optim_config['lr'], 
                                    momentum=optim_config.get('momentum', 0.9))
            else:
                raise ValueError(f"Unsupported optimizer: {optim_config['type']}")
            
            epochs = config.get('epochs', 10)
            best_val_acc = 0.0
            history = {'train_loss': [], 'val_acc': []}
            
            print(f"Starting training for {epochs} epochs...")
            
            for epoch in range(epochs):
                # Training phase
                model.train()
                train_loss = 0.0
                for batch_idx, (data, target) in enumerate(train_loader):
                    data, target = data.to(device), target.to(device)
                    
                    optimizer.zero_grad()
                    output = model(data)
                    loss = criterion(output, target)
                    loss.backward()
                    optimizer.step()
                    
                    train_loss += loss.item()
                
                # Validation phase
                model.eval()
                val_preds = []
                val_targets = []
                with torch.no_grad():
                    for data, target in val_loader:
                        data, target = data.to(device), target.to(device)
                        output = model(data)
                        pred = output.argmax(dim=1)
                        val_preds.extend(pred.cpu().numpy())
                        val_targets.extend(target.cpu().numpy())
                
                val_acc = accuracy_score(val_targets, val_preds)
                avg_train_loss = train_loss / len(train_loader)
                
                history['train_loss'].append(avg_train_loss)
                history['val_acc'].append(val_acc)
                
                print(f'Epoch {epoch+1}/{epochs} - '
                      f'Train Loss: {avg_train_loss:.4f}, '
                      f'Val Acc: {val_acc:.4f}')
                
                if val_acc > best_val_acc:
                    best_val_acc = val_acc
                    torch.save(model.state_dict(), 'best_model.pth')
                    print(f"  âœ“ New best model saved (val_acc: {val_acc:.4f})")
            
            return history, best_val_acc

        def evaluate_model(model, test_loader, device):
            """Evaluate the model on test set"""
            model.eval()
            test_preds = []
            test_targets = []
            
            print("Running evaluation on test set...")
            
            with torch.no_grad():
                for data, target in test_loader:
                    data, target = data.to(device), target.to(device)
                    output = model(data)
                    pred = output.argmax(dim=1)
                    test_preds.extend(pred.cpu().numpy())
                    test_targets.extend(target.cpu().numpy())
            
            accuracy = accuracy_score(test_targets, test_preds)
            f1 = f1_score(test_targets, test_preds, average='weighted')
            
            print(f"Test Accuracy: {accuracy:.4f}")
            print(f"Test F1 Score: {f1:.4f}")
            
            return accuracy, f1

        # Main training execution
        try:
            # Set device
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            print(f"Using device: {device}")
            
            # Load data loaders
            train_loader, val_loader, test_loader = load_data_loaders(args.data_path)
            
            # Create model
            model = DynamicCNN(
                config=config,
                input_shape=input_shape,
                num_classes=args.num_classes
            ).to(device)
            
            print(f"Model created with {sum(p.numel() for p in model.parameters())} parameters")
            
            # Train model
            history, best_val_acc = train_model(model, train_loader, val_loader, config, device)
            
            # Load best model and evaluate
            print("Loading best model for final evaluation...")
            model.load_state_dict(torch.load('best_model.pth'))
            test_accuracy, test_f1 = evaluate_model(model, test_loader, device)
            
            # Save model and results
            output_dir = '/tmp/output'
            Path(output_dir).mkdir(parents=True, exist_ok=True)
            
            model_save_path = os.path.join(output_dir, 'trained_model.pth')
            torch.save(model.state_dict(), model_save_path)
            
            # Save training results
            results = {
                'test_accuracy': test_accuracy,
                'test_f1_score': test_f1,
                'best_val_accuracy': best_val_acc,
                'history': history,
                'model_config': config,
                'input_shape': input_shape,
                'num_classes': args.num_classes
            }
            
            with open(os.path.join(output_dir, 'training_results.json'), 'w') as f:
                json.dump(results, f, indent=2)
            
            # Save outputs for pipeline
            with open(args.test_accuracy, 'w') as f:
                f.write(f"{test_accuracy:.6f}")
            
            with open(args.test_f1_score, 'w') as f:
                f.write(f"{test_f1:.6f}")
            
            with open(args.best_val_accuracy, 'w') as f:
                f.write(f"{best_val_acc:.6f}")
            
            with open(args.model_path, 'w') as f:
                f.write(model_save_path)
            
            print("=== TRAINING COMPLETED SUCCESSFULLY ===")
            print(f"   Test Accuracy: {test_accuracy:.4f}")
            print(f"   Test F1 Score: {test_f1:.4f}")
            print(f"   Best Val Accuracy: {best_val_acc:.4f}")
            print(f"   Model saved to: {model_save_path}")
            
        except Exception as e:
            print(f"=== TRAINING FAILED ===")
            print(f"Error: {e}")
            import traceback
            traceback.print_exc()
            
            # Save failure outputs
            with open(args.test_accuracy, 'w') as f:
                f.write("0.0")
            with open(args.test_f1_score, 'w') as f:
                f.write("0.0")
            with open(args.best_val_accuracy, 'w') as f:
                f.write("0.0")
            with open(args.model_path, 'w') as f:
                f.write("/tmp/failed_model.pth")
            
            raise
        
        print("Training & evaluation brick completed successfully!")
    args:
      - --data_path
      - {inputValue: data_path}
      - --num_classes
      - {inputValue: num_classes}
      - --input_shape
      - {inputValue: input_shape}
      - --model_config
      - {inputValue: model_config}
      - --test_accuracy
      - {outputPath: test_accuracy}
      - --test_f1_score
      - {outputPath: test_f1_score}
      - --best_val_accuracy
      - {outputPath: best_val_accuracy}
      - --model_path
      - {outputPath: model_path}
