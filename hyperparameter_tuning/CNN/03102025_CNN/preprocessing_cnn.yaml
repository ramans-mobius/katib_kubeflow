name: CNN Data Preprocessing
description: Universal data preprocessing for CNN models (standalone)

inputs:
  - name: data_path
    type: String
    description: Path to raw data from data loading brick
    
  - name: dataset_name
    type: String
    description: Name of the dataset (e.g., mnist, cifar10, or custom)
    default: ""
    
  - name: batch_size
    type: Integer
    description: Batch size for data loaders
    default: 64
    
  - name: validation_split
    type: Float
    description: Fraction of data to use for validation
    default: 0.2
    
  - name: input_size
    type: String
    description: Input image size as "width,height"
    default: "224,224"

outputs:
  - name: processed_data_path
    type: String
    description: Path to processed data and data loaders

  - name: num_classes
    type: Integer
    description: Number of classes detected

  - name: input_shape
    type: String
    description: Input shape as "channels,height,width"

implementation:
  container:
    image: nikhilv215/nesy-factory:v18
    command:
      - python3
      - -u
      - -c
      - |
        import os
        import sys
        import json
        import pickle
        import argparse
        from pathlib import Path
        import torch
        from torch.utils.data import DataLoader, random_split
        import torchvision
        import torchvision.transforms as transforms
        from torchvision.datasets import ImageFolder
        import numpy as np
        from PIL import Image
        
        # ============================================================
        # UNIVERSAL TRANSFORMS
        # ============================================================
        def get_universal_transforms(input_size=(224, 224), is_training=False):
            """Universal transforms that work for any image dataset"""
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            
            transform_list = []
            
            if is_training:
                transform_list.extend([
                    transforms.RandomHorizontalFlip(p=0.5),
                    transforms.RandomRotation(degrees=15),
                    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
                    transforms.RandomResizedCrop(input_size, scale=(0.8, 1.0))
                ])
            else:
                transform_list.extend([
                    transforms.Resize(input_size),
                    transforms.CenterCrop(input_size)
                ])
            
            transform_list.extend([
                transforms.ToTensor(),
                transforms.Normalize(mean, std)
            ])
            
            return transforms.Compose(transform_list)
        
        # ============================================================
        # DATASET STRUCTURE DETECTION
        # ============================================================
        def detect_dataset_structure(data_path):
            """Auto-detect the structure of any dataset"""
            print(f"Scanning dataset structure in: {data_path}")
            
            if not os.path.exists(data_path):
                raise ValueError(f"Data path does not exist: {data_path}")
            
            structures = {
                'imagefolder_split': os.path.exists(os.path.join(data_path, 'train')) and 
                                    os.path.exists(os.path.join(data_path, 'test')),
                'imagefolder_train_only': os.path.exists(os.path.join(data_path, 'train')) and 
                                         not os.path.exists(os.path.join(data_path, 'test')),
                'imagefolder_flat': any(os.path.isdir(os.path.join(data_path, d)) for d in os.listdir(data_path) if not d.startswith('.')),
                'single_directory': any(f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')) 
                                      for f in os.listdir(data_path))
            }
            
            if structures['imagefolder_split']:
                return 'imagefolder_split'
            elif structures['imagefolder_train_only']:
                return 'imagefolder_train_only'
            elif structures['imagefolder_flat']:
                return 'imagefolder_flat'
            elif structures['single_directory']:
                return 'single_directory'
            else:
                return 'unknown'
        
        # ============================================================
        # CLASS DETECTION
        # ============================================================
        def get_num_classes_from_dataset(dataset):
            """Extract number of classes from any dataset type"""
            print("Detecting number of classes...")
            
            try:
                # Method 1: Direct targets access
                if hasattr(dataset, 'targets'):
                    targets = dataset.targets
                    if isinstance(targets, (list, np.ndarray)):
                        unique_labels = np.unique(targets)
                        num_classes = len(unique_labels)
                        print(f"  Found {num_classes} classes from targets: {unique_labels}")
                        return num_classes
                
                # Method 2: Classes attribute
                if hasattr(dataset, 'classes'):
                    num_classes = len(dataset.classes)
                    print(f"  Found {num_classes} classes from classes attribute")
                    return num_classes
                
                # Method 3: For ImageFolder, check class_to_idx
                if hasattr(dataset, 'class_to_idx'):
                    num_classes = len(dataset.class_to_idx)
                    print(f"  Found {num_classes} classes from class_to_idx")
                    return num_classes
                
                # Method 4: Sample dataset to find unique labels
                print("  Sampling dataset to detect classes...")
                all_labels = set()
                sample_size = min(1000, len(dataset))
                
                for i in range(sample_size):
                    try:
                        _, label = dataset[i]
                        all_labels.add(label)
                    except Exception:
                        continue
                
                if all_labels:
                    num_classes = len(all_labels)
                    print(f"  Found {num_classes} classes by sampling: {sorted(all_labels)}")
                    return num_classes
                
                # Default
                print("  Warning: Could not detect classes, defaulting to 2")
                return 2
                
            except Exception as e:
                print(f"  Warning: Error detecting classes: {e}, defaulting to 2")
                return 2
        
        # ============================================================
        # TORCHVISION DATASET LOADER
        # ============================================================
        def load_torchvision_dataset(dataset_name, data_path, is_training=True, input_size=(224, 224)):
            """Load torchvision datasets (CIFAR10, CIFAR100, MNIST, etc.)"""
            
            dataset_map = {
                'cifar10': torchvision.datasets.CIFAR10,
                'cifar100': torchvision.datasets.CIFAR100,
                'mnist': torchvision.datasets.MNIST,
                'fashionmnist': torchvision.datasets.FashionMNIST,
                'kmnist': torchvision.datasets.KMNIST,
            }
            
            dataset_name_lower = dataset_name.lower()
            
            if dataset_name_lower not in dataset_map:
                return None
            
            dataset_class = dataset_map[dataset_name_lower]
            print(f"Loading torchvision dataset: {dataset_name}")
            
            # Special handling for MNIST-like datasets
            if dataset_name_lower in ['mnist', 'fashionmnist', 'kmnist']:
                transform_list = []
                if is_training:
                    transform_list.extend([
                        transforms.RandomHorizontalFlip(p=0.5),
                        transforms.RandomRotation(degrees=15),
                    ])
                transform_list.extend([
                    transforms.Resize(input_size),
                    transforms.Grayscale(3),
                    transforms.ToTensor(),
                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
                ])
                transform = transforms.Compose(transform_list)
            else:
                # CIFAR datasets
                transform_list = []
                if is_training:
                    transform_list.extend([
                        transforms.RandomHorizontalFlip(p=0.5),
                        transforms.RandomCrop(32, padding=4),
                    ])
                transform_list.extend([
                    transforms.Resize(input_size),
                    transforms.ToTensor(),
                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
                ])
                transform = transforms.Compose(transform_list)
            
            try:
                dataset = dataset_class(
                    root=data_path,
                    train=is_training,
                    download=False,
                    transform=transform
                )
                return dataset
            except Exception as e:
                print(f"Error loading {dataset_name}: {e}")
                return None
        
        # ============================================================
        # UNIVERSAL DATASET LOADER
        # ============================================================
        def load_any_dataset(data_path, dataset_name=None, is_training=True, input_size=(224, 224)):
            """Load any dataset regardless of structure"""
            
            # Try torchvision datasets first
            if dataset_name:
                torchvision_dataset = load_torchvision_dataset(dataset_name, data_path, is_training, input_size)
                if torchvision_dataset is not None:
                    return torchvision_dataset
            
            structure = detect_dataset_structure(data_path)
            print(f"Detected dataset structure: {structure}")
            
            transform = get_universal_transforms(input_size, is_training=is_training)
            
            if structure == 'imagefolder_split':
                split_dir = 'train' if is_training else 'test'
                dataset_path = os.path.join(data_path, split_dir)
                return ImageFolder(root=dataset_path, transform=transform)
            
            elif structure == 'imagefolder_train_only':
                if is_training:
                    return ImageFolder(
                        root=os.path.join(data_path, 'train'),
                        transform=transform
                    )
                else:
                    return ImageFolder(
                        root=os.path.join(data_path, 'train'),
                        transform=get_universal_transforms(input_size, is_training=False)
                    )
            
            elif structure == 'imagefolder_flat':
                return ImageFolder(root=data_path, transform=transform)
            
            elif structure == 'single_directory':
                class SingleClassDataset(torch.utils.data.Dataset):
                    def __init__(self, data_path, transform=None):
                        self.data_path = data_path
                        self.transform = transform
                        self.image_files = [f for f in os.listdir(data_path)
                                          if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]
                        print(f"  Found {len(self.image_files)} images in single directory")
                    
                    def __len__(self):
                        return len(self.image_files)
                    
                    def __getitem__(self, idx):
                        img_path = os.path.join(self.data_path, self.image_files[idx])
                        image = Image.open(img_path).convert('RGB')
                        if self.transform:
                            image = self.transform(image)
                        return image, 0
                
                return SingleClassDataset(data_path, transform)
            
            else:
                raise ValueError(f"Unsupported dataset structure: {structure}")
        
        # ============================================================
        # MAIN PREPROCESSING
        # ============================================================
        parser = argparse.ArgumentParser()
        parser.add_argument("--data_path", type=str, required=True)
        parser.add_argument("--dataset_name", type=str, required=True)
        parser.add_argument("--batch_size", type=int, required=True)
        parser.add_argument("--validation_split", type=float, required=True)
        parser.add_argument("--input_size", type=str, required=True)
        parser.add_argument("--processed_data_path", type=str, required=True)
        parser.add_argument("--num_classes", type=str, required=True)
        parser.add_argument("--input_shape", type=str, required=True)
        args = parser.parse_args()
        
        print("=== CNN DATA PREPROCESSING ===")
        print(f"Data path: {args.data_path}")
        print(f"Dataset name: {args.dataset_name}")
        print(f"Input size: {args.input_size}")
        print(f"Batch size: {args.batch_size}")
        print(f"Validation split: {args.validation_split}")
        
        try:
            # Parse input size
            input_size = tuple(map(int, args.input_size.split(',')))
            print(f"Parsed input size: {input_size}")
            
            # Load datasets
            print("\nLoading training data...")
            train_dataset = load_any_dataset(args.data_path, dataset_name=args.dataset_name, 
                                            is_training=True, input_size=input_size)
            
            print("\nLoading test data...")
            test_dataset = load_any_dataset(args.data_path, dataset_name=args.dataset_name,
                                           is_training=False, input_size=input_size)
            
            # Auto-detect number of classes
            num_classes = get_num_classes_from_dataset(train_dataset)
            
            # Handle case where train and test are the same
            if len(train_dataset) == len(test_dataset):
                print("\nNo separate test set found, splitting training data...")
                total_size = len(train_dataset)
                test_size = int(0.2 * total_size)
                train_size = total_size - test_size
                train_dataset, test_dataset = random_split(train_dataset, [train_size, test_size])
            
            # Split train into train and validation
            val_size = int(len(train_dataset) * args.validation_split)
            train_size = len(train_dataset) - val_size
            
            print(f"\nDataset splits:")
            print(f"  Training: {train_size} samples")
            print(f"  Validation: {val_size} samples")
            print(f"  Test: {len(test_dataset)} samples")
            print(f"  Classes: {num_classes}")
            
            train_subset, val_subset = random_split(train_dataset, [train_size, val_size])
            
            # Create data loaders
            train_loader = DataLoader(train_subset, batch_size=args.batch_size, 
                                     shuffle=True, num_workers=2)
            val_loader = DataLoader(val_subset, batch_size=args.batch_size,
                                   shuffle=False, num_workers=2)
            test_loader = DataLoader(test_dataset, batch_size=args.batch_size,
                                    shuffle=False, num_workers=2)
            
            # Get input shape from sample batch
            sample_batch, _ = next(iter(train_loader))
            input_shape = sample_batch.shape[1:]
            input_shape_str = f"{input_shape[0]},{input_shape[1]},{input_shape[2]}"
            
            # Save processed data
            output_path = os.path.join(args.data_path, 'preprocessed')
            Path(output_path).mkdir(parents=True, exist_ok=True)
            
            torch.save(train_loader, os.path.join(output_path, 'train_loader.pth'))
            torch.save(val_loader, os.path.join(output_path, 'val_loader.pth'))
            torch.save(test_loader, os.path.join(output_path, 'test_loader.pth'))
            
            # Save data info
            data_info = {
                'dataset_name': args.dataset_name,
                'data_path': args.data_path,
                'num_classes': num_classes,
                'input_shape': input_shape,
                'batch_size': args.batch_size,
                'input_size': input_size,
                'preprocessed_path': output_path
            }
            
            with open(os.path.join(output_path, 'data_info.pkl'), 'wb') as f:
                pickle.dump(data_info, f)
            
            # Write outputs for pipeline
            with open(args.processed_data_path, 'w') as f:
                f.write(output_path)
            
            with open(args.num_classes, 'w') as f:
                f.write(str(num_classes))
            
            with open(args.input_shape, 'w') as f:
                f.write(input_shape_str)
            
            print("\n=== PREPROCESSING COMPLETED ===")
            print(f"Output path: {output_path}")
            print(f"Number of classes: {num_classes}")
            print(f"Input shape: {input_shape_str}")
            print(f"Train batches: {len(train_loader)}")
            print(f"Val batches: {len(val_loader)}")
            print(f"Test batches: {len(test_loader)}")
            
        except Exception as e:
            print(f"\n=== PREPROCESSING FAILED ===")
            print(f"Error: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)
        
        print("\n=== PREPROCESSING BRICK COMPLETED ===")
    
    args:
      - --data_path
      - {inputValue: data_path}
      - --dataset_name
      - {inputValue: dataset_name}
      - --batch_size
      - {inputValue: batch_size}
      - --validation_split
      - {inputValue: validation_split}
      - --input_size
      - {inputValue: input_size}
      - --processed_data_path
      - {outputPath: processed_data_path}
      - --num_classes
      - {outputPath: num_classes}
      - --input_shape
      - {outputPath: input_shape}
