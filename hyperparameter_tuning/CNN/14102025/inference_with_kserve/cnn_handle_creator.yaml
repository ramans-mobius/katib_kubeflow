name: Inference 2 CNN Handler Creator
description: Creates a TorchServe handler for CNN model inference
inputs:
  - name: model_config
    type: String
  - name: class_labels
    type: String
  - name: inference_config
    type: String
outputs:
  - name: cnn_handler
    type: String
implementation:
  container:
    image: python:3.9
    command:
      - sh
      - -c
      - |
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import json
        import argparse
        import os
        
        parser = argparse.ArgumentParser()
        parser.add_argument('--model_config', type=str, required=True)
        parser.add_argument('--class_labels', type=str, required=True)
        parser.add_argument('--inference_config', type=str, required=True)
        parser.add_argument('--cnn_handler', type=str, required=True)
        args = parser.parse_args()
        
        with open(args.model_config, 'r') as f:
            model_config = json.load(f)
        with open(args.class_labels, 'r') as f:
            class_labels = json.load(f)
        with open(args.inference_config, 'r') as f:
            inference_config = json.load(f)
        
        lines = []
        lines.append("import torch")
        lines.append("import torch.nn.functional as F")
        lines.append("from torchvision import transforms")
        lines.append("from PIL import Image")
        lines.append("import json")
        lines.append("import io")
        lines.append("import logging")
        lines.append("import os")
        lines.append("")
        lines.append("logger = logging.getLogger(__name__)")
        lines.append("")
        lines.append("class CNNImageHandler:")
        lines.append("    def __init__(self):")
        lines.append("        self.model = None")
        lines.append(f"        self.class_names = {class_labels}")
        lines.append("        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')")
        lines.append("        self.initialized = False")
        lines.append("        self.transform = transforms.Compose([")
        lines.append("            transforms.Resize(256),")
        lines.append("            transforms.CenterCrop(224),")
        lines.append("            transforms.ToTensor(),")
        lines.append("            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])")
        lines.append("        ])")
        lines.append(f"        self.model_config = {model_config}")
        lines.append(f"        self.inference_config = {inference_config}")
        lines.append("")
        lines.append("    def initialize(self, context):")
        lines.append("        try:")
        lines.append("            properties = context.system_properties")
        lines.append("            model_dir = properties.get('model_dir')")
        lines.append("            model_pt_path = os.path.join(model_dir, 'model.pth')")
        lines.append("            if not os.path.isfile(model_pt_path):")
        lines.append("                raise RuntimeError('Model file not found: ' + model_pt_path)")
        lines.append("            self.model = context.model")
        lines.append("            self.model.to(self.device)")
        lines.append("            self.model.eval()")
        lines.append("            self.initialized = True")
        lines.append("        except Exception as e:")
        lines.append("            logger.error(f'Model initialization failed: {str(e)}')")
        lines.append("            raise")
        lines.append("")
        lines.append("    def preprocess(self, data):")
        lines.append("        try:")
        lines.append("            images = []")
        lines.append("            for row in data:")
        lines.append("                image = row.get('data') or row.get('body')")
        lines.append("                if isinstance(image, (bytearray, bytes)):")
        lines.append("                    image = Image.open(io.BytesIO(image)).convert('RGB')")
        lines.append("                elif isinstance(image, str):")
        lines.append("                    import base64")
        lines.append("                    image_data = base64.b64decode(image)")
        lines.append("                    image = Image.open(io.BytesIO(image_data)).convert('RGB')")
        lines.append("                else:")
        lines.append("                    raise ValueError('Unsupported image format')")
        lines.append("                image = self.transform(image)")
        lines.append("                images.append(image)")
        lines.append("            batch = torch.stack(images).to(self.device)")
        lines.append("            return batch")
        lines.append("        except Exception as e:")
        lines.append("            logger.error(f'Preprocessing failed: {str(e)}')")
        lines.append("            raise")
        lines.append("")
        lines.append("    def inference(self, model_input):")
        lines.append("        try:")
        lines.append("            with torch.no_grad():")
        lines.append("                outputs = self.model(model_input)")
        lines.append("                probabilities = F.softmax(outputs, dim=1)")
        lines.append("                return probabilities")
        lines.append("        except Exception as e:")
        lines.append("            logger.error(f'Inference failed: {str(e)}')")
        lines.append("            raise")
        lines.append("")
        lines.append("    def postprocess(self, inference_output):")
        lines.append("        try:")
        lines.append("            confidences, predicted_indices = torch.max(inference_output, 1)")
        lines.append("            results = []")
        lines.append("            for i, (conf, pred_idx) in enumerate(zip(confidences, predicted_indices)):")
        lines.append("                pred_idx = pred_idx.item()")
        lines.append("                confidence = conf.item()")
        lines.append("                class_name = self.class_names.get(str(pred_idx), f'class_{pred_idx}')")
        lines.append("                result = {")
        lines.append("                    'predicted_class': class_name,")
        lines.append("                    'class_id': pred_idx,")
        lines.append("                    'confidence': float(confidence),")
        lines.append("                    'all_probabilities': {")
        lines.append("                        self.class_names.get(str(j), f'class_{j}'): float(prob)")
        lines.append("                        for j, prob in enumerate(inference_output[i])")
        lines.append("                    }")
        lines.append("                }")
        lines.append("                results.append(result)")
        lines.append("            return results")
        lines.append("        except Exception as e:")
        lines.append("            logger.error(f'Postprocessing failed: {str(e)}')")
        lines.append("            raise")
        lines.append("")
        lines.append("    def handle(self, data, context):")
        lines.append("        try:")
        lines.append("            if not self.initialized:")
        lines.append("                self.initialize(context)")
        lines.append("            model_input = self.preprocess(data)")
        lines.append("            model_output = self.inference(model_input)")
        lines.append("            result = self.postprocess(model_output)")
        lines.append("            return result")
        lines.append("        except Exception as e:")
        lines.append("            logger.error(f'Handler failed: {str(e)}')")
        lines.append("            return [{'error': str(e)}]")
        lines.append("")
        lines.append("_service = CNNImageHandler()")
        lines.append("")
        lines.append("def handle(data, context):")
        lines.append("    return _service.handle(data, context)")
        
        handler_content = "\n".join(lines)
        
        os.makedirs(args.cnn_handler, exist_ok=True)
        handler_path = os.path.join(args.cnn_handler, 'handler.py')
        with open(handler_path, 'w') as f:
            f.write(handler_content)
        
        print(f"CNN handler created at: {handler_path}")
    args:
      - --model_config
      - {inputPath: model_config}
      - --class_labels
      - {inputPath: class_labels}
      - --inference_config
      - {inputPath: inference_config}
      - --cnn_handler
      - {outputPath: cnn_handler}
