name: Inference CNN Handler Creator
description: Creates a TorchServe handler for CNN model inference
inputs:
  - name: model_config
    type: String
  - name: class_labels
    type: String
  - name: inference_config
    type: String
outputs:
  - name: cnn_handler
    type: String
implementation:
  container:
    image: python:3.9
    command:
      - sh
      - -c
      - |
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import json
        import argparse
        import os
        
        parser = argparse.ArgumentParser()
        parser.add_argument('--model_config', type=str, required=True)
        parser.add_argument('--class_labels', type=str, required=True)
        parser.add_argument('--inference_config', type=str, required=True)
        parser.add_argument('--cnn_handler', type=str, required=True)
        args = parser.parse_args()
        
        with open(args.model_config, 'r') as f:
            model_config = json.load(f)
        with open(args.class_labels, 'r') as f:
            class_labels = json.load(f)
        with open(args.inference_config, 'r') as f:
            inference_config = json.load(f)
        
        handler_content = "import torch\n"
        handler_content += "import torch.nn.functional as F\n"
        handler_content += "from torchvision import transforms\n"
        handler_content += "from PIL import Image\n"
        handler_content += "import json\n"
        handler_content += "import io\n"
        handler_content += "import logging\n"
        handler_content += "import os\n\n"
        handler_content += "logger = logging.getLogger(__name__)\n\n"
        handler_content += "class CNNImageHandler:\n"
        handler_content += "    def __init__(self):\n"
        handler_content += "        self.model = None\n"
        handler_content += f"        self.class_names = {class_labels}\n"
        handler_content += "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
        handler_content += "        self.initialized = False\n"
        handler_content += "        self.transform = transforms.Compose([\n"
        handler_content += "            transforms.Resize(256),\n"
        handler_content += "            transforms.CenterCrop(224),\n"
        handler_content += "            transforms.ToTensor(),\n"
        handler_content += "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n"
        handler_content += "        ])\n"
        handler_content += f"        self.model_config = {model_config}\n"
        handler_content += f"        self.inference_config = {inference_config}\n\n"
        handler_content += "    def initialize(self, context):\n"
        handler_content += "        try:\n"
        handler_content += "            properties = context.system_properties\n"
        handler_content += "            model_dir = properties.get('model_dir')\n"
        handler_content += "            model_pt_path = os.path.join(model_dir, 'model.pth')\n"
        handler_content += "            if not os.path.isfile(model_pt_path):\n"
        handler_content += "                raise RuntimeError('Model file not found: ' + model_pt_path)\n"
        handler_content += "            self.model = context.model\n"
        handler_content += "            self.model.to(self.device)\n"
        handler_content += "            self.model.eval()\n"
        handler_content += "            self.initialized = True\n"
        handler_content += "        except Exception as e:\n"
        handler_content += "            logger.error(f'Model initialization failed: {str(e)}')\n"
        handler_content += "            raise\n\n"
        handler_content += "    def preprocess(self, data):\n"
        handler_content += "        try:\n"
        handler_content += "            images = []\n"
        handler_content += "            for row in data:\n"
        handler_content += "                image = row.get('data') or row.get('body')\n"
        handler_content += "                if isinstance(image, (bytearray, bytes)):\n"
        handler_content += "                    image = Image.open(io.BytesIO(image)).convert('RGB')\n"
        handler_content += "                elif isinstance(image, str):\n"
        handler_content += "                    import base64\n"
        handler_content += "                    image_data = base64.b64decode(image)\n"
        handler_content += "                    image = Image.open(io.BytesIO(image_data)).convert('RGB')\n"
        handler_content += "                else:\n"
        handler_content += "                    raise ValueError('Unsupported image format')\n"
        handler_content += "                image = self.transform(image)\n"
        handler_content += "                images.append(image)\n"
        handler_content += "            batch = torch.stack(images).to(self.device)\n"
        handler_content += "            return batch\n"
        handler_content += "        except Exception as e:\n"
        handler_content += "            logger.error(f'Preprocessing failed: {str(e)}')\n"
        handler_content += "            raise\n\n"
        handler_content += "    def inference(self, model_input):\n"
        handler_content += "        try:\n"
        handler_content += "            with torch.no_grad():\n"
        handler_content += "                outputs = self.model(model_input)\n"
        handler_content += "                probabilities = F.softmax(outputs, dim=1)\n"
        handler_content += "                return probabilities\n"
        handler_content += "        except Exception as e:\n"
        handler_content += "            logger.error(f'Inference failed: {str(e)}')\n"
        handler_content += "            raise\n\n"
        handler_content += "    def postprocess(self, inference_output):\n"
        handler_content += "        try:\n"
        handler_content += "            confidences, predicted_indices = torch.max(inference_output, 1)\n"
        handler_content += "            results = []\n"
        handler_content += "            for i, (conf, pred_idx) in enumerate(zip(confidences, predicted_indices)):\n"
        handler_content += "                pred_idx = pred_idx.item()\n"
        handler_content += "                confidence = conf.item()\n"
        handler_content += "                class_name = self.class_names.get(str(pred_idx), f'class_{pred_idx}')\n"
        handler_content += "                result = {\n"
        handler_content += "                    'predicted_class': class_name,\n"
        handler_content += "                    'class_id': pred_idx,\n"
        handler_content += "                    'confidence': float(confidence),\n"
        handler_content += "                    'all_probabilities': {\n"
        handler_content += "                        self.class_names.get(str(j), f'class_{j}'): float(prob)\n"
        handler_content += "                        for j, prob in enumerate(inference_output[i])\n"
        handler_content += "                    }\n"
        handler_content += "                }\n"
        handler_content += "                results.append(result)\n"
        handler_content += "            return results\n"
        handler_content += "        except Exception as e:\n"
        handler_content += "            logger.error(f'Postprocessing failed: {str(e)}')\n"
        handler_content += "            raise\n\n"
        handler_content += "    def handle(self, data, context):\n"
        handler_content += "        try:\n"
        handler_content += "            if not self.initialized:\n"
        handler_content += "                self.initialize(context)\n"
        handler_content += "            model_input = self.preprocess(data)\n"
        handler_content += "            model_output = self.inference(model_input)\n"
        handler_content += "            result = self.postprocess(model_output)\n"
        handler_content += "            return result\n"
        handler_content += "        except Exception as e:\n"
        handler_content += "            logger.error(f'Handler failed: {str(e)}')\n"
        handler_content += "            return [{'error': str(e)}]\n\n"
        handler_content += "_service = CNNImageHandler()\n\n"
        handler_content += "def handle(data, context):\n"
        handler_content += "    return _service.handle(data, context)\n"
        
        os.makedirs(args.cnn_handler, exist_ok=True)
        handler_path = os.path.join(args.cnn_handler, 'handler.py')
        with open(handler_path, 'w') as f:
            f.write(handler_content)
        
        print(f"CNN handler created at: {handler_path}")
    args:
      - --model_config
      - {inputPath: model_config}
      - --class_labels
      - {inputPath: class_labels}
      - --inference_config
      - {inputPath: inference_config}
      - --cnn_handler
      - {outputPath: cnn_handler}
