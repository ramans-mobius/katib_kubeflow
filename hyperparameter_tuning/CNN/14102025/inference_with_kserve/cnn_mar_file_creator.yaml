name: Inference CNN MAR File Creator with nesy-factory
description: Creates MAR file using nesy-factory CNN registry
inputs:
  - name: model_weights
    type: Model
  - name: cnn_handler
    type: String
  - name: model_config
    type: String
  - name: model_name
    type: String
outputs:
  - name: mar_file_out
    type: String
  - name: mar_creation_log
    type: String
implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v19
    command:
      - sh
      - -c
      - |
        pip install torch-model-archiver torchvision
        python3 -c "
        import base64
        encoded_script = b'''
        import torch
        import torch.nn as nn
        import json
        import os
        import sys

        sys.path.insert(0, '/usr/local/lib/python3.10/site-packages')

        try:
            from nesy_factory.CNNs.registry import create_model as create_cnn_model
        except ImportError as e:
            try:
                from nesy_factory.CNNs import BaseCNN, ResNet, EfficientNet, MobileNet, DenseNet, SimpleCNN
                def create_cnn_model(arch_name, config):
                    arch_name = arch_name.lower()
                    if arch_name == 'resnet':
                        return ResNet(config)
                    elif arch_name == 'efficientnet':
                        return EfficientNet(config)
                    elif arch_name == 'mobilenet':
                        return MobileNet(config)
                    elif arch_name == 'densenet':
                        return DenseNet(config)
                    elif arch_name == 'simple_cnn':
                        return SimpleCNN(config)
                    else:
                        return BaseCNN(config)
            except ImportError as e2:
                raise ImportError(\\\"Cannot load nesy-factory CNN models\\\")

        class CNNModel(nn.Module):
            def __init__(self):
                super(CNNModel, self).__init__()
                with open(os.path.join(os.path.dirname(__file__), 'model_config.json'), 'r') as f:
                    config_data = json.load(f)
                model_config = config_data.get('model_info', {})
                architecture = model_config.get('architecture', 'BaseCNN')
                self.model = create_cnn_model(architecture, model_config)
            def forward(self, x):
                return self.model(x)

        def model_fn(model_dir):
            config_path = os.path.join(model_dir, 'model_config.json')
            with open(config_path, 'r') as f:
                config_data = json.load(f)
            model_config = config_data.get('model_info', {})
            architecture = model_config.get('architecture', 'BaseCNN')
            model = create_cnn_model(architecture, model_config)
            model_files = [f for f in os.listdir(model_dir) if f.endswith(('.pth', '.pt'))]
            if not model_files:
                raise FileNotFoundError(f\\\"No model weights found in {model_dir}\\\")
            weights_path = os.path.join(model_dir, model_files[0])
            checkpoint = torch.load(weights_path, map_location='cpu')
            if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                model.load_state_dict(checkpoint['model_state_dict'])
            elif isinstance(checkpoint, dict):
                model.load_state_dict(checkpoint)
            else:
                model.load_state_dict(checkpoint)
            model.eval()
            return model
        '''
        print(base64.b64encode(encoded_script).decode())
        " > /tmp/encoded_model.txt
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import os
        import subprocess
        import json
        import argparse
        import shutil
        import base64

        parser = argparse.ArgumentParser()
        parser.add_argument('--model_weights', type=str, required=True)
        parser.add_argument('--cnn_handler', type=str, required=True)
        parser.add_argument('--model_config', type=str, required=True)
        parser.add_argument('--model_name', type=str, default='cnn-model')
        parser.add_argument('--mar_file_out', type=str, required=True)
        parser.add_argument('--mar_creation_log', type=str, required=True)
        args = parser.parse_args()

        with open(args.model_config, 'r') as f:
            model_config_data = json.load(f)
        model_config = model_config_data.get('model_info', {})
        architecture = model_config.get('architecture', 'BaseCNN')

        with open('/tmp/encoded_model.txt', 'r') as f:
            encoded_script = f.read().strip()

        model_content = base64.b64decode(encoded_script).decode()

        try:
            os.makedirs('/tmp/cnn_model', exist_ok=True)
            
            weights_found = False
            if os.path.isdir(args.model_weights):
                for file in os.listdir(args.model_weights):
                    if file.endswith(('.pth', '.pt')):
                        weights_src = os.path.join(args.model_weights, file)
                        weights_dest = '/tmp/cnn_model/model.pth'
                        shutil.copy2(weights_src, weights_dest)
                        weights_found = True
                        break
            else:
                weights_dest = '/tmp/cnn_model/model.pth'
                shutil.copy2(args.model_weights, weights_dest)
                weights_found = True
            
            if not weights_found:
                raise FileNotFoundError(f"No .pth or .pt files found in {args.model_weights}")
            
            handler_src = os.path.join(args.cnn_handler, 'handler.py')
            handler_dest = '/tmp/cnn_model/handler.py'
            shutil.copy2(handler_src, handler_dest)
            
            config_dest = '/tmp/cnn_model/model_config.json'
            shutil.copy2(args.model_config, config_dest)
            
            with open('/tmp/cnn_model/model.py', 'w') as f:
                f.write(model_content)
            
            os.makedirs(args.mar_file_out, exist_ok=True)
            
            cmd = [
                'torch-model-archiver',
                '--model-name', args.model_name,
                '--version', '1.0',
                '--model-file', '/tmp/cnn_model/model.py',
                '--serialized-file', '/tmp/cnn_model/model.pth',
                '--handler', '/tmp/cnn_model/handler.py',
                '--extra-files', '/tmp/cnn_model/model_config.json',
                '--export-path', args.mar_file_out,
                '--force'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            
            mar_file = os.path.join(args.mar_file_out, f"{args.model_name}.mar")
            if os.path.exists(mar_file):
                file_size = os.path.getsize(mar_file)
                log_data = {
                    'status': 'success',
                    'mar_file': mar_file,
                    'file_size': file_size,
                    'model_name': args.model_name,
                    'architecture': architecture,
                    'output': result.stdout
                }
            else:
                raise Exception("MAR file not found after creation")
                
        except subprocess.CalledProcessError as e:
            error_msg = f"MAR creation failed: {e.stderr}"
            log_data = {
                'status': 'failed',
                'error': error_msg,
                'stdout': e.stdout,
                'stderr': e.stderr
            }
            raise
        except Exception as e:
            error_msg = f"MAR creation error: {str(e)}"
            log_data = {
                'status': 'failed',
                'error': error_msg
            }
            raise
        
        finally:
            os.makedirs(os.path.dirname(args.mar_creation_log), exist_ok=True)
            with open(args.mar_creation_log, 'w') as f:
                json.dump(log_data, f, indent=2)
    args:
      - --model_weights
      - {inputPath: model_weights}
      - --cnn_handler
      - {inputPath: cnn_handler}
      - --model_config
      - {inputPath: model_config}
      - --model_name
      - {inputValue: model_name}
      - --mar_file_out
      - {outputPath: mar_file_out}
      - --mar_creation_log
      - {outputPath: mar_creation_log}
