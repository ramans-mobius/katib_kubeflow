name: Inference CNN MAR File Creator with nesy-factory
description: Creates MAR file using nesy-factory CNN registry
inputs:
  - name: model_weights
    type: Model
  - name: cnn_handler
    type: String
  - name: model_config
    type: String
  - name: model_name
    type: String
    default: "cnn-model"
outputs:
  - name: mar_file_out
    type: String
  - name: mar_creation_log
    type: String
implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v19
    command:
      - sh
      - -c
      - |
        pip install torch-model-archiver torchvision
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import os
        import subprocess
        import json
        import argparse
        import shutil
        
        parser = argparse.ArgumentParser()
        parser.add_argument('--model_weights', type=str, required=True)
        parser.add_argument('--cnn_handler', type=str, required=True)
        parser.add_argument('--model_config', type=str, required=True)
        parser.add_argument('--model_name', type=str, default='cnn-model')
        parser.add_argument('--mar_file_out', type=str, required=True)
        parser.add_argument('--mar_creation_log', type=str, required=True)
        args = parser.parse_args()
        
        with open(args.model_config, 'r') as f:
            model_config_data = json.load(f)
        
        model_config = model_config_data.get('model_info', {})
        architecture = model_config.get('architecture', 'BaseCNN')
        
        model_content = "import torch\n"
        model_content += "import torch.nn as nn\n"
        model_content += "import json\n"
        model_content += "import os\n"
        model_content += "import sys\n\n"
        model_content += "sys.path.insert(0, '/usr/local/lib/python3.10/site-packages')\n\n"
        model_content += "try:\n"
        model_content += "    from nesy_factory.CNNs.registry import create_model as create_cnn_model\n"
        model_content += "except ImportError as e:\n"
        model_content += "    try:\n"
        model_content += "        from nesy_factory.CNNs import BaseCNN, ResNet, EfficientNet, MobileNet, DenseNet, SimpleCNN\n"
        model_content += "        def create_cnn_model(arch_name, config):\n"
        model_content += "            arch_name = arch_name.lower()\n"
        model_content += "            if arch_name == 'resnet':\n"
        model_content += "                return ResNet(config)\n"
        model_content += "            elif arch_name == 'efficientnet':\n"
        model_content += "                return EfficientNet(config)\n"
        model_content += "            elif arch_name == 'mobilenet':\n"
        model_content += "                return MobileNet(config)\n"
        model_content += "            elif arch_name == 'densenet':\n"
        model_content += "                return DenseNet(config)\n"
        model_content += "            elif arch_name == 'simple_cnn':\n"
        model_content += "                return SimpleCNN(config)\n"
        model_content += "            else:\n"
        model_content += "                return BaseCNN(config)\n"
        model_content += "    except ImportError as e2:\n"
        model_content += "        raise ImportError('Cannot load nesy-factory CNN models')\n\n"
        model_content += "class CNNModel(nn.Module):\n"
        model_content += "    def __init__(self):\n"
        model_content += "        super(CNNModel, self).__init__()\n"
        model_content += "        with open(os.path.join(os.path.dirname(__file__), 'model_config.json'), 'r') as f:\n"
        model_content += "            config_data = json.load(f)\n"
        model_content += "        model_config = config_data.get('model_info', {})\n"
        model_content += "        architecture = model_config.get('architecture', 'BaseCNN')\n"
        model_content += "        self.model = create_cnn_model(architecture, model_config)\n"
        model_content += "    def forward(self, x):\n"
        model_content += "        return self.model(x)\n\n"
        model_content += "def model_fn(model_dir):\n"
        model_content += "    config_path = os.path.join(model_dir, 'model_config.json')\n"
        model_content += "    with open(config_path, 'r') as f:\n"
        model_content += "        config_data = json.load(f)\n"
        model_content += "    model_config = config_data.get('model_info', {})\n"
        model_content += "    architecture = model_config.get('architecture', 'BaseCNN')\n"
        model_content += "    model = create_cnn_model(architecture, model_config)\n"
        model_content += "    model_files = [f for f in os.listdir(model_dir) if f.endswith(('.pth', '.pt'))]\n"
        model_content += "    if not model_files:\n"
        model_content += "        raise FileNotFoundError(f'No model weights found in {model_dir}')\n"
        model_content += "    weights_path = os.path.join(model_dir, model_files[0])\n"
        model_content += "    checkpoint = torch.load(weights_path, map_location='cpu')\n"
        model_content += "    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n"
        model_content += "        model.load_state_dict(checkpoint['model_state_dict'])\n"
        model_content += "    elif isinstance(checkpoint, dict):\n"
        model_content += "        model.load_state_dict(checkpoint)\n"
        model_content += "    else:\n"
        model_content += "        model.load_state_dict(checkpoint)\n"
        model_content += "    model.eval()\n"
        model_content += "    return model\n"
        
        try:
            os.makedirs('/tmp/cnn_model', exist_ok=True)
            
            weights_found = False
            if os.path.isdir(args.model_weights):
                for file in os.listdir(args.model_weights):
                    if file.endswith(('.pth', '.pt')):
                        weights_src = os.path.join(args.model_weights, file)
                        weights_dest = '/tmp/cnn_model/model.pth'
                        shutil.copy2(weights_src, weights_dest)
                        weights_found = True
                        break
            else:
                weights_dest = '/tmp/cnn_model/model.pth'
                shutil.copy2(args.model_weights, weights_dest)
                weights_found = True
            
            if not weights_found:
                raise FileNotFoundError(f"No .pth or .pt files found in {args.model_weights}")
            
            handler_src = os.path.join(args.cnn_handler, 'handler.py')
            handler_dest = '/tmp/cnn_model/handler.py'
            shutil.copy2(handler_src, handler_dest)
            
            config_dest = '/tmp/cnn_model/model_config.json'
            shutil.copy2(args.model_config, config_dest)
            
            with open('/tmp/cnn_model/model.py', 'w') as f:
                f.write(model_content)
            
            os.makedirs(args.mar_file_out, exist_ok=True)
            
            cmd = [
                'torch-model-archiver',
                '--model-name', args.model_name,
                '--version', '1.0',
                '--model-file', '/tmp/cnn_model/model.py',
                '--serialized-file', '/tmp/cnn_model/model.pth',
                '--handler', '/tmp/cnn_model/handler.py',
                '--extra-files', '/tmp/cnn_model/model_config.json',
                '--export-path', args.mar_file_out,
                '--force'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            
            mar_file = os.path.join(args.mar_file_out, f"{args.model_name}.mar")
            if os.path.exists(mar_file):
                file_size = os.path.getsize(mar_file)
                log_data = {
                    'status': 'success',
                    'mar_file': mar_file,
                    'file_size': file_size,
                    'model_name': args.model_name,
                    'architecture': architecture,
                    'output': result.stdout
                }
            else:
                raise Exception("MAR file not found after creation")
                
        except subprocess.CalledProcessError as e:
            error_msg = f"MAR creation failed: {e.stderr}"
            log_data = {
                'status': 'failed',
                'error': error_msg,
                'stdout': e.stdout,
                'stderr': e.stderr
            }
            raise
        except Exception as e:
            error_msg = f"MAR creation error: {str(e)}"
            log_data = {
                'status': 'failed',
                'error': error_msg
            }
            raise
        
        finally:
            os.makedirs(os.path.dirname(args.mar_creation_log), exist_ok=True)
            with open(args.mar_creation_log, 'w') as f:
                json.dump(log_data, f, indent=2)
    args:
      - --model_weights
      - {inputPath: model_weights}
      - --cnn_handler
      - {inputPath: cnn_handler}
      - --model_config
      - {inputPath: model_config}
      - --model_name
      - {inputValue: model_name}
      - --mar_file_out
      - {outputPath: mar_file_out}
      - --mar_creation_log
      - {outputPath: mar_creation_log}
