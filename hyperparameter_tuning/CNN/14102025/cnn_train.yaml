name: dataset CNN Train Model
description: Trains CNN model using provided data and configuration
inputs:
  - name: data_path
    type: Dataset
  - name: model
    type: Model
  - name: config
    type: String
outputs:
  - name: trained_model
    type: Model
  - name: training_history
    type: String

implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v19
    command:
      - sh
      - -c
      - |
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import torch, argparse, pickle, os, json, torch.nn as nn, torch.optim as optim

        parser = argparse.ArgumentParser()
        parser.add_argument('--data_path', type=str, required=True)
        parser.add_argument('--model', type=str, required=True)
        parser.add_argument('--config', type=str, required=True)
        parser.add_argument('--trained_model', type=str, required=True)
        parser.add_argument('--training_history', type=str, required=True)
        args = parser.parse_args()

        print(f"Data path: {args.data_path}")
        print(f"Model path: {args.model}")
        print(f"Config: {args.config}")

        # Load data
        try:
            with open(args.data_path, "rb") as f:
                processed_data = pickle.load(f)
            print("Successfully loaded data")
        except Exception as e:
            print(f"Error loading data: {e}")
            exit(1)

        # Load config
        try:
            config = json.loads(args.config)
            training_config = config.get('training', {})
            print("Successfully loaded config")
        except Exception as e:
            print(f"Error loading config: {e}")
            exit(1)

        # Load model
        try:
            from nesy_factory.CNNs.factory import CNNFactory
            model_config = config.get('model', {})
            model = CNNFactory.create_model(model_config.get('architecture', 'resnet'), model_config)
            model.load_state_dict(torch.load(args.model, map_location=torch.device('cpu')))
            print("Successfully loaded model")
        except Exception as e:
            print(f"Error loading model: {e}")
            exit(1)

        # Extract training parameters
        epochs = training_config.get('epochs', 5)
        learning_rate = training_config.get('learning_rate', 0.001)
        batch_size = training_config.get('batch_size', 32)

        print(f"Training parameters: epochs={epochs}, lr={learning_rate}, batch_size={batch_size}")

        # Training setup
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = model.to(device)
        optimizer = optim.Adam(model.parameters(), lr=learning_rate)
        criterion = nn.CrossEntropyLoss()

        # Get data loaders
        train_loader = processed_data.get('train_loader')
        val_loader = processed_data.get('val_loader')

        if train_loader is None:
            print("ERROR: train_loader not found in data")
            exit(1)

        # Training loop
        training_history = []
        best_val_acc = 0.0

        print("Starting training...")
        for epoch in range(epochs):
            # Training phase
            model.train()
            train_loss = 0.0
            train_correct = 0
            train_total = 0
            
            for data, target in train_loader:
                data, target = data.to(device), target.to(device)
                
                optimizer.zero_grad()
                output = model(data)
                loss = criterion(output, target)
                loss.backward()
                optimizer.step()
                
                train_loss += loss.item()
                _, predicted = output.max(1)
                train_total += target.size(0)
                train_correct += predicted.eq(target).sum().item()
            
            train_acc = 100.0 * train_correct / train_total
            avg_train_loss = train_loss / len(train_loader)
            
            # Validation phase
            val_acc = 0.0
            if val_loader:
                model.eval()
                val_correct = 0
                val_total = 0
                
                with torch.no_grad():
                    for data, target in val_loader:
                        data, target = data.to(device), target.to(device)
                        output = model(data)
                        _, predicted = output.max(1)
                        val_total += target.size(0)
                        val_correct += predicted.eq(target).sum().item()
                
                val_acc = 100.0 * val_correct / val_total
                best_val_acc = max(best_val_acc, val_acc)
            
            # Save epoch results
            epoch_info = {
                'epoch': epoch + 1,
                'train_loss': avg_train_loss,
                'train_accuracy': train_acc,
                'val_accuracy': val_acc
            }
            training_history.append(epoch_info)
            
            print(f"Epoch {epoch+1}/{epochs} | Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%")

        # Save trained model and history
        os.makedirs(os.path.dirname(args.trained_model), exist_ok=True)
        os.makedirs(os.path.dirname(args.training_history), exist_ok=True)

        torch.save(model.state_dict(), args.trained_model)
        with open(args.training_history, 'w') as f:
            json.dump(training_history, f, indent=2)

        print(f"Training completed! Best validation accuracy: {best_val_acc:.2f}%")
        print(f"Trained model saved to {args.trained_model}")
        print(f"Training history saved to {args.training_history}")

    args:
      - --data_path
      - {inputPath: data_path}
      - --model
      - {inputPath: model}
      - --config
      - {inputValue: config}
      - --trained_model
      - {outputPath: trained_model}
      - --training_history
      - {outputPath: training_history}
