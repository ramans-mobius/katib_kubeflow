name: CNN Train Model
description: Trains CNN model using provided data and configuration
inputs:
  - name: data_path
    type: Dataset
  - name: model
    type: Model
  - name: config
    type: String
outputs:
  - name: trained_model
    type: Model
  - name: training_history
    type: String

implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v19
    command:
      - python3
      - -u
      - -c
      - |
        import torch, argparse, pickle, os, json, torch.nn as nn, torch.optim as optim

        parser = argparse.ArgumentParser()
        parser.add_argument('--data_path', type=str, required=True)
        parser.add_argument('--model', type=str, required=True)
        parser.add_argument('--config', type=str, required=True)
        parser.add_argument('--trained_model', type=str, required=True)
        parser.add_argument('--training_history', type=str, required=True)
        args = parser.parse_args()

        print("Starting CNN Training")
        print(f"Data path: {args.data_path}")
        print(f"Model path: {args.model}")

        try:
            with open(args.data_path, "rb") as f:
                processed_data = pickle.load(f)
            print("Data loaded successfully")
        except Exception as e:
            print(f"Error loading data: {e}")
            exit(1)

        try:
            config = json.loads(args.config)
            training_config = config.get('training', {})
            model_config = config.get('model', {})
            print("Config loaded successfully")
        except Exception as e:
            print(f"Error loading config: {e}")
            exit(1)

        try:
            from nesy_factory.CNNs.factory import CNNFactory
            model = CNNFactory.create_model(model_config.get('architecture', 'resnet'), model_config)
            model.load_state_dict(torch.load(args.model, map_location=torch.device('cpu')))
            print("Model loaded successfully")
        except Exception as e:
            print(f"Error loading model: {e}")
            exit(1)

        epochs = training_config.get('epochs', 5)
        optimizer_config = training_config.get('optimizer', {})
        learning_rate = optimizer_config.get('learning_rate', 0.001)

        print(f"Training parameters: epochs={epochs}, lr={learning_rate}")

        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = model.to(device)
        
        optimizer = optim.AdamW(model.parameters(), lr=learning_rate, 
                              weight_decay=optimizer_config.get('weight_decay', 0.0001))
        criterion = nn.CrossEntropyLoss()

        train_loader = processed_data.train_loader
        val_loader = getattr(processed_data, 'test_loader', None)

        if train_loader is None:
            print("train_loader not found in data")
            exit(1)

        training_history = []
        best_val_acc = 0.0
        best_model_state = model.state_dict().copy()

        print("Starting training...")
        for epoch in range(epochs):
            model.train()
            train_loss = 0.0
            train_correct = 0
            train_total = 0
            
            for batch_idx, (data, target) in enumerate(train_loader):
                data, target = data.to(device), target.to(device)
                
                optimizer.zero_grad()
                output = model(data)
                loss = criterion(output, target)
                loss.backward()
                optimizer.step()
                
                train_loss += loss.item()
                _, predicted = output.max(1)
                train_total += target.size(0)
                train_correct += predicted.eq(target).sum().item()
            
            train_acc = 100.0 * train_correct / train_total
            avg_train_loss = train_loss / len(train_loader)
            
            val_acc = 0.0
            val_loss = 0.0
            if val_loader:
                model.eval()
                val_correct = 0
                val_total = 0
                
                with torch.no_grad():
                    for data, target in val_loader:
                        data, target = data.to(device), target.to(device)
                        output = model(data)
                        loss = criterion(output, target)
                        val_loss += loss.item()
                        _, predicted = output.max(1)
                        val_total += target.size(0)
                        val_correct += predicted.eq(target).sum().item()
                
                val_acc = 100.0 * val_correct / val_total
                avg_val_loss = val_loss / len(val_loader)
                if val_acc > best_val_acc:
                    best_val_acc = val_acc
                    best_model_state = model.state_dict().copy()
            else:
                avg_val_loss = 0.0
            
            epoch_info = {
                'epoch': epoch + 1,
                'train_loss': avg_train_loss,
                'train_accuracy': train_acc,
                'val_loss': avg_val_loss,
                'val_accuracy': val_acc
            }
            training_history.append(epoch_info)
            
            print(f'Epoch {epoch+1}/{epochs}: Train Loss: {avg_train_loss:.4f}, Acc: {train_acc:.2f}% | Val Loss: {avg_val_loss:.4f}, Acc: {val_acc:.2f}%')

        model.load_state_dict(best_model_state)

        os.makedirs(os.path.dirname(args.trained_model), exist_ok=True)
        os.makedirs(os.path.dirname(args.training_history), exist_ok=True)

        torch.save(model.state_dict(), args.trained_model)
        with open(args.training_history, 'w') as f:
            json.dump(training_history, f, indent=2)

        print(f"Training complete! Best val accuracy: {best_val_acc:.2f}%")
        print(f"Model saved to: {args.trained_model}")
        print(f"Training history saved to: {args.training_history}")
    args:
      - --data_path
      - {inputPath: data_path}
      - --model
      - {inputPath: model}
      - --config
      - {inputValue: config}
      - --trained_model
      - {outputPath: trained_model}
      - --training_history
      - {outputPath: training_history}
