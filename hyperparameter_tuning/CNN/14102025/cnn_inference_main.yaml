name: CNN Inference
description: Runs CNN inference on images using downloaded model artifacts
inputs:
  - name: model_weights
    type: Model
    description: Trained CNN model weights
  - name: model_config
    type: String
    description: Model configuration JSON
  - name: class_labels
    type: String
    description: Class labels mapping JSON
  - name: inference_config
    type: String
    description: Inference configuration JSON
  - name: preprocess_data
    type: Dataset
    description: Preprocessed dataset for reference
  - name: input_images
    type: String
    description: "Path to input images OR '-1' to use test data from preprocess_data"
outputs:
  - name: inference_results
    type: String
    description: JSON results of inference predictions
  - name: predictions
    type: Dataset
    description: Detailed predictions with confidence scores

implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v19
    command:
      - sh
      - -c
      - |
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import torch, argparse, pickle, os, json, torch.nn as nn, torch.nn.functional as F
        import sys, numpy as np
        import io

        print("=== CNN Inference ===")

        # Define the same helper classes as in train brick for pickle compatibility
        class LabeledDataset:
            def __init__(self, dataset=None, label_mapping=None):
                self.dataset = dataset or []
                self.label_mapping = label_mapping or {}
            def __len__(self):
                try:
                    if hasattr(self.dataset, '__len__'):
                        return len(self.dataset)
                    return 100
                except:
                    return 100
            def __getitem__(self, idx):
                try:
                    if hasattr(self.dataset, '__getitem__'):
                        item = self.dataset[idx]
                        if isinstance(item, tuple) and len(item) == 2:
                            data, label = item
                        elif isinstance(item, dict):
                            data = item.get('image_data')
                            label = item.get('label', 0)
                            return data, label
                        else:
                            return item, 0
                except:
                    pass
                return torch.randn(3, 224, 224), 0

        class SimpleDataset:
            def __init__(self, data=None):
                self.data = data or []
            def __len__(self):
                try:
                    if hasattr(self.data, '__len__'):
                        length = len(self.data)
                        if length > 0:
                            return length
                except:
                    pass
                return 100
            def __getitem__(self, idx):
                try:
                    if hasattr(self.data, '__getitem__'):
                        item = self.data[idx]
                        if isinstance(item, tuple) and len(item) == 2:
                            return item
                        elif isinstance(item, dict):
                            data = item.get('image_data')
                            label = item.get('label', 0)
                            return data, label
                        else:
                            return item, 0
                except:
                    pass
                return torch.randn(3, 224, 224), 0

        class DataWrapper:
            def __init__(self, data_dict=None):
                if data_dict:
                    self.__dict__.update(data_dict)

        class SafeUnpickler(pickle.Unpickler):
            def find_class(self, module, name):
                try:
                    return super().find_class(module, name)
                except:
                    if name == 'LabeledDataset':
                        return LabeledDataset
                    elif name == 'DataWrapper':
                        return DataWrapper
                    elif name == 'SimpleDataset':
                        return SimpleDataset
                    else:
                        class FallbackClass:
                            def __init__(self, *args, **kwargs):
                                pass
                        return FallbackClass

        # Simple image preprocessing without torchvision
        def simple_preprocess(image_tensor, target_size=(224, 224)):
            """Basic image preprocessing without torchvision"""
            if len(image_tensor.shape) == 3:
                image_tensor = image_tensor.unsqueeze(0)
            
            # Simple resize (nearest neighbor)
            if image_tensor.shape[2] != target_size[0] or image_tensor.shape[3] != target_size[1]:
                # Basic interpolation for resizing
                import torch.nn.functional as F
                image_tensor = F.interpolate(image_tensor, size=target_size, mode='nearest')
            
            # Normalize (ImageNet stats)
            mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)
            std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)
            image_tensor = (image_tensor - mean) / std
            
            return image_tensor

        parser = argparse.ArgumentParser()
        parser.add_argument('--model_weights', type=str, required=True)
        parser.add_argument('--model_config', type=str, required=True)
        parser.add_argument('--class_labels', type=str, required=True)
        parser.add_argument('--inference_config', type=str, required=True)
        parser.add_argument('--preprocess_data', type=str, required=True)
        parser.add_argument('--input_images', type=str, required=True)
        parser.add_argument('--inference_results', type=str, required=True)
        parser.add_argument('--predictions', type=str, required=True)
        args = parser.parse_args()

        print("=== CNN Inference Configuration ===")
        print(f"Input images parameter: {args.input_images}")

        # Load configurations
        with open(args.model_config, 'r') as f:
            model_config = json.load(f)
        with open(args.class_labels, 'r') as f:
            class_labels = json.load(f)
        with open(args.inference_config, 'r') as f:
            inference_config = json.load(f)

        print("Loaded configurations:")
        print(f"Model: {model_config.get('model_info', {}).get('name', 'Unknown')}")
        print(f"Classes: {len(class_labels)}")

        # Load model using the same approach as train brick
        try:
            sys.path.insert(0, '/usr/local/lib/python3.10/site-packages')
            from nesy_factory.CNNs.registry import create_model as create_cnn_model
            
            model_architecture = model_config.get('model_info', {}).get('architecture', 'resnet')
            model = create_cnn_model(model_architecture, model_config.get('model_info', {}))
            
            # Load checkpoint using same method as train brick
            checkpoint = torch.load(args.model_weights, map_location='cpu')
            if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                model.load_state_dict(checkpoint['model_state_dict'])
            else:
                model.load_state_dict(checkpoint)
            
            model.eval()
            print(f"Model loaded: {model_architecture}")
            
        except Exception as e:
            print(f"Error loading model: {e}")
            # Fallback to basic CNN (same as train brick)
            class SimpleCNN(nn.Module):
                def __init__(self, num_classes):
                    super(SimpleCNN, self).__init__()
                    self.features = nn.Sequential(
                        nn.Conv2d(3, 64, kernel_size=3, padding=1),
                        nn.ReLU(),
                        nn.MaxPool2d(2),
                        nn.Conv2d(64, 128, kernel_size=3, padding=1),
                        nn.ReLU(),
                        nn.MaxPool2d(2),
                    )
                    self.classifier = nn.Linear(128 * 56 * 56, num_classes)
                
                def forward(self, x):
                    x = self.features(x)
                    x = x.view(x.size(0), -1)
                    x = self.classifier(x)
                    return x
            
            num_classes = len(class_labels)
            model = SimpleCNN(num_classes)
            checkpoint = torch.load(args.model_weights, map_location='cpu')
            if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                model.load_state_dict(checkpoint['model_state_dict'])
            else:
                model.load_state_dict(checkpoint)
            model.eval()
            print("Loaded fallback SimpleCNN model")

        predictions = []
        
        # Handle input_images parameter
        if args.input_images == "-1":
            print("Using test data from preprocessed dataset")
            # Load preprocess_data using same unpickling method as train brick
            try:
                with open(args.preprocess_data, 'rb') as f:
                    raw_data = f.read()
                
                processed_data = SafeUnpickler(io.BytesIO(raw_data)).load()
                print("Preprocessed data loaded successfully")
                
                if hasattr(processed_data, 'test_loader'):
                    test_loader = processed_data.test_loader
                    print("Found test_loader in preprocessed data")
                    
                    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
                    model.to(device)
                    
                    all_predictions = []
                    with torch.no_grad():
                        for batch_idx, (images, labels) in enumerate(test_loader):
                            if batch_idx >= 5:  # Limit to first 5 batches for demo
                                break
                            
                            # Preprocess images if needed
                            images = simple_preprocess(images)
                            images = images.to(device)
                            
                            outputs = model(images)
                            probabilities = F.softmax(outputs, dim=1)
                            confidences, predicted = torch.max(probabilities, 1)
                            
                            for i in range(len(images)):
                                pred_info = {
                                    'batch': batch_idx,
                                    'sample': i,
                                    'true_label': int(labels[i].item()) if labels is not None else None,
                                    'true_class': class_labels.get(str(int(labels[i].item())), f"class_{int(labels[i].item())}") if labels is not None else "unknown",
                                    'predicted_label': int(predicted[i].item()),
                                    'predicted_class': class_labels.get(str(int(predicted[i].item())), f"class_{int(predicted[i].item())}"),
                                    'confidence': float(confidences[i].item()),
                                    'all_probabilities': {
                                        class_labels.get(str(j), f"class_{j}"): float(probabilities[i][j].item())
                                        for j in range(len(class_labels))
                                    }
                                }
                                all_predictions.append(pred_info)
                                predictions.append(pred_info)
                    
                    print(f"Processed {len(all_predictions)} test samples from preprocessed data")
                    
                else:
                    print("No test loader found in dataset")
                    raise Exception("No test data available")
                    
            except Exception as e:
                print(f"Error using test data: {e}")
                # Create dummy inference as fallback
                device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
                model.to(device)
                dummy_image = torch.randn(1, 3, 224, 224).to(device)
                with torch.no_grad():
                    output = model(dummy_image)
                    probabilities = F.softmax(output, dim=1)
                    confidence, predicted = torch.max(probabilities, 1)
                    
                    pred_info = {
                        'sample': 'dummy',
                        'predicted_label': int(predicted.item()),
                        'predicted_class': class_labels.get(str(int(predicted.item())), f"class_{int(predicted.item())}"),
                        'confidence': float(confidence.item()),
                        'note': 'Dummy inference - no real data available'
                    }
                    predictions.append(pred_info)
                    
        else:
            print(f"Using external input from: {args.input_images}")
            try:
                # For external inputs, we'll use a simple approach with dummy data
                # since we don't have torchvision for image loading
                print("Note: External image loading requires torchvision. Using dummy data instead.")
                
                device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
                model.to(device)
                
                # Create dummy batch for demonstration
                dummy_batch = torch.randn(4, 3, 224, 224).to(device)
                with torch.no_grad():
                    outputs = model(dummy_batch)
                    probabilities = F.softmax(outputs, dim=1)
                    confidences, predicted = torch.max(probabilities, 1)
                    
                    for i in range(len(dummy_batch)):
                        pred_info = {
                            'sample': i,
                            'predicted_label': int(predicted[i].item()),
                            'predicted_class': class_labels.get(str(int(predicted[i].item())), f"class_{int(predicted[i].item())}"),
                            'confidence': float(confidences[i].item()),
                            'note': 'Dummy data - external input not fully supported without torchvision',
                            'all_probabilities': {
                                class_labels.get(str(j), f"class_{j}"): float(probabilities[i][j].item())
                                for j in range(len(class_labels))
                            }
                        }
                        predictions.append(pred_info)
                
                print(f"Created {len(predictions)} dummy predictions for demonstration")
                    
            except Exception as e:
                print(f"Error with external input: {e}")

        # Prepare results
        inference_results = {
            'model_info': model_config.get('model_info', {}),
            'inference_config': inference_config,
            'total_predictions': len(predictions),
            'predictions': predictions,
            'class_mapping': class_labels,
            'input_source': 'test_data' if args.input_images == "-1" else 'external_input',
            'summary': {
                'samples_processed': len(predictions),
                'average_confidence': np.mean([p.get('confidence', 0) for p in predictions if 'confidence' in p]) if predictions else 0
            }
        }

        # Save results
        os.makedirs(os.path.dirname(args.inference_results) or ".", exist_ok=True)
        with open(args.inference_results, 'w') as f:
            json.dump(inference_results, f, indent=2)

        os.makedirs(os.path.dirname(args.predictions) or ".", exist_ok=True)
        with open(args.predictions, 'w') as f:
            json.dump(predictions, f, indent=2)

        print(f"Inference completed. Processed {len(predictions)} samples.")
        print(f"Input source: {'Test data' if args.input_images == '-1' else 'External input'}")
        print(f"Results saved to {args.inference_results}")

    args:
      - --model_weights
      - { inputPath: model_weights }
      - --model_config
      - { inputPath: model_config }
      - --class_labels
      - { inputPath: class_labels }
      - --inference_config
      - { inputPath: inference_config }
      - --preprocess_data
      - { inputPath: preprocess_data }
      - --input_images
      - { inputValue: input_images }
      - --inference_results
      - { outputPath: inference_results }
      - --predictions
      - { outputPath: predictions }
