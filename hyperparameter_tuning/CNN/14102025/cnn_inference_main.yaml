name: 2 CNN Inference
description: Runs CNN inference on images using downloaded model artifacts
inputs:
  - name: model_weights
    type: Model
    description: Trained CNN model weights
  - name: model_config
    type: String
    description: Model configuration JSON
  - name: class_labels
    type: String
    description: Class labels mapping JSON
  - name: inference_config
    type: String
    description: Inference configuration JSON
  - name: preprocess_data
    type: Dataset
    description: Preprocessed dataset for reference
  - name: input_images
    type: String
    description: "Path to input images OR '-1' to use test data from preprocess_data"
outputs:
  - name: inference_results
    type: String
    description: JSON results of inference predictions
  - name: predictions
    type: Dataset
    description: Detailed predictions with confidence scores

implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v19
    command:
      - sh
      - -c
      - |
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import torch, argparse, pickle, os, json, torch.nn as nn, torch.nn.functional as F
        import sys, numpy as np
        import io

        print("=== CNN Inference ===")

        class LabeledDataset:
            def __init__(self, dataset=None, label_mapping=None):
                self.dataset = dataset or []
                self.label_mapping = label_mapping or {}
            def __len__(self):
                try:
                    if hasattr(self.dataset, '__len__'):
                        return len(self.dataset)
                    return 100
                except:
                    return 100
            def __getitem__(self, idx):
                try:
                    if hasattr(self.dataset, '__getitem__'):
                        item = self.dataset[idx]
                        if isinstance(item, tuple) and len(item) == 2:
                            data, label = item
                        elif isinstance(item, dict):
                            data = item.get('image_data')
                            label = item.get('label', 0)
                            return data, label
                        else:
                            return item, 0
                except:
                    pass
                return torch.randn(3, 224, 224), 0

        class SimpleDataset:
            def __init__(self, data=None):
                self.data = data or []
            def __len__(self):
                try:
                    if hasattr(self.data, '__len__'):
                        length = len(self.data)
                        if length > 0:
                            return length
                except:
                    pass
                return 100
            def __getitem__(self, idx):
                try:
                    if hasattr(self.data, '__getitem__'):
                        item = self.data[idx]
                        if isinstance(item, tuple) and len(item) == 2:
                            return item
                        elif isinstance(item, dict):
                            data = item.get('image_data')
                            label = item.get('label', 0)
                            return data, label
                        else:
                            return item, 0
                except:
                    pass
                return torch.randn(3, 224, 224), 0

        class DataWrapper:
            def __init__(self, data_dict=None):
                if data_dict:
                    self.__dict__.update(data_dict)

        class SafeUnpickler(pickle.Unpickler):
            def find_class(self, module, name):
                try:
                    return super().find_class(module, name)
                except:
                    if name == 'LabeledDataset':
                        return LabeledDataset
                    elif name == 'DataWrapper':
                        return DataWrapper
                    elif name == 'SimpleDataset':
                        return SimpleDataset
                    else:
                        class FallbackClass:
                            def __init__(self, *args, **kwargs):
                                pass
                        return FallbackClass

        parser = argparse.ArgumentParser()
        parser.add_argument('--model_weights', type=str, required=True)
        parser.add_argument('--model_config', type=str, required=True)
        parser.add_argument('--class_labels', type=str, required=True)
        parser.add_argument('--inference_config', type=str, required=True)
        parser.add_argument('--preprocess_data', type=str, required=True)
        parser.add_argument('--input_images', type=str, required=True)
        parser.add_argument('--inference_results', type=str, required=True)
        parser.add_argument('--predictions', type=str, required=True)
        args = parser.parse_args()

        print("Input images parameter:", args.input_images)

        with open(args.model_config, 'r') as f:
            model_config_data = json.load(f)
        with open(args.class_labels, 'r') as f:
            class_labels_json = json.load(f)
        with open(args.inference_config, 'r') as f:
            inference_config = json.load(f)

        print("Model config num_classes:", model_config_data.get('model_info', {}).get('num_classes'))
        print("Class labels count:", len(class_labels_json))

        with open(args.preprocess_data, 'rb') as f:
            raw_data = f.read()
        processed_data = SafeUnpickler(io.BytesIO(raw_data)).load()

        real_class_names = []
        if hasattr(processed_data, 'class_names'):
            real_class_names = processed_data.class_names
            print("Real class names from data:", real_class_names)
        elif hasattr(processed_data, 'label_to_idx'):
            real_class_names = list(processed_data.label_to_idx.keys())
            print("Real class names from label_to_idx:", real_class_names)

        actual_num_classes = len(real_class_names) if real_class_names else len(class_labels_json)
        print("Actual number of classes:", actual_num_classes)

        model_config = model_config_data.get('model_info', {}).copy()
        if 'num_classes' in model_config:
            model_config['output_dim'] = actual_num_classes
            print("Fixed model config - added output_dim:", actual_num_classes)

        print("Loading model...")
        try:
            sys.path.insert(0, '/usr/local/lib/python3.10/site-packages')
            from nesy_factory.CNNs.registry import create_model as create_cnn_model
            
            model_architecture = model_config.get('architecture', 'resnet')
            print("Creating model with architecture:", model_architecture)
            print("Model config for creation:", model_config)
            
            model = create_cnn_model(model_architecture, model_config)
            
            checkpoint = torch.load(args.model_weights, map_location='cpu')
            if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                model.load_state_dict(checkpoint['model_state_dict'])
            else:
                model.load_state_dict(checkpoint)
            
            model.eval()
            print("Model loaded successfully:", model_architecture)
            
        except Exception as e:
            print("Error loading model:", e)
            print("Trying to load as full model...")
            try:
                model = torch.load(args.model_weights, map_location='cpu')
                if isinstance(model, dict):
                    raise Exception("Checkpoint dict, not model")
                model.eval()
                print("Loaded as full model object")
            except Exception as e2:
                print("Failed to load as full model:", e2)
                sys.exit(1)

        predictions = []
        
        if args.input_images == "-1":
            print("Using test data from preprocessed dataset")
            try:
                if hasattr(processed_data, 'test_loader'):
                    test_loader = processed_data.test_loader
                    print("Found test_loader")
                    
                    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
                    model.to(device)
                    
                    all_predictions = []
                    with torch.no_grad():
                        for batch_idx, (images, labels) in enumerate(test_loader):
                            if batch_idx >= 3:
                                break
                            
                            images = images.to(device)
                            outputs = model(images)
                            probabilities = F.softmax(outputs, dim=1)
                            confidences, predicted = torch.max(probabilities, 1)
                            
                            for i in range(len(images)):
                                predicted_idx = int(predicted[i].item())
                                true_idx = int(labels[i].item()) if labels is not None else None
                                
                                if real_class_names and predicted_idx < len(real_class_names):
                                    predicted_class = real_class_names[predicted_idx]
                                else:
                                    predicted_class = class_labels_json.get(str(predicted_idx), f"class_{predicted_idx}")
                                
                                if real_class_names and true_idx is not None and true_idx < len(real_class_names):
                                    true_class = real_class_names[true_idx]
                                elif true_idx is not None:
                                    true_class = class_labels_json.get(str(true_idx), f"class_{true_idx}")
                                else:
                                    true_class = "unknown"
                                
                                pred_info = {
                                    'batch': batch_idx,
                                    'sample': i,
                                    'true_label': true_idx,
                                    'true_class': true_class,
                                    'predicted_label': predicted_idx,
                                    'predicted_class': predicted_class,
                                    'confidence': float(confidences[i].item()),
                                    'all_probabilities': {}
                                }
                                
                                for j in range(actual_num_classes):
                                    if real_class_names and j < len(real_class_names):
                                        class_name = real_class_names[j]
                                    else:
                                        class_name = class_labels_json.get(str(j), f"class_{j}")
                                    pred_info['all_probabilities'][class_name] = float(probabilities[i][j].item())
                                
                                all_predictions.append(pred_info)
                                predictions.append(pred_info)
                    
                    print(f"Processed {len(all_predictions)} test samples")
                    
                else:
                    print("No test loader found")
                    raise Exception("No test data")
                    
            except Exception as e:
                print("Error using test data:", e)
                device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
                model.to(device)
                dummy_image = torch.randn(1, 3, 224, 224).to(device)
                with torch.no_grad():
                    output = model(dummy_image)
                    probabilities = F.softmax(output, dim=1)
                    confidence, predicted = torch.max(probabilities, 1)
                    
                    predicted_idx = int(predicted.item())
                    if real_class_names and predicted_idx < len(real_class_names):
                        predicted_class = real_class_names[predicted_idx]
                    else:
                        predicted_class = class_labels_json.get(str(predicted_idx), f"class_{predicted_idx}")
                    
                    pred_info = {
                        'sample': 'dummy',
                        'predicted_label': predicted_idx,
                        'predicted_class': predicted_class,
                        'confidence': float(confidence.item()),
                        'note': 'Dummy inference'
                    }
                    predictions.append(pred_info)

        final_class_mapping = {}
        for i in range(actual_num_classes):
            if real_class_names and i < len(real_class_names):
                final_class_mapping[str(i)] = real_class_names[i]
            else:
                final_class_mapping[str(i)] = class_labels_json.get(str(i), f"class_{i}")

        inference_results = {
            'model_info': model_config_data.get('model_info', {}),
            'inference_config': inference_config,
            'total_predictions': len(predictions),
            'predictions': predictions,
            'class_mapping': final_class_mapping,
            'input_source': 'test_data' if args.input_images == "-1" else 'external_input',
            'summary': {
                'samples_processed': len(predictions),
                'average_confidence': np.mean([p.get('confidence', 0) for p in predictions if 'confidence' in p]) if predictions else 0
            }
        }

        os.makedirs(os.path.dirname(args.inference_results) or ".", exist_ok=True)
        with open(args.inference_results, 'w') as f:
            json.dump(inference_results, f, indent=2)

        os.makedirs(os.path.dirname(args.predictions) or ".", exist_ok=True)
        with open(args.predictions, 'w') as f:
            json.dump(predictions, f, indent=2)

        print(f"Inference completed. Processed {len(predictions)} samples.")
        print("Real class names used:", real_class_names)
        print("Results saved")

    args:
      - --model_weights
      - { inputPath: model_weights }
      - --model_config
      - { inputPath: model_config }
      - --class_labels
      - { inputPath: class_labels }
      - --inference_config
      - { inputPath: inference_config }
      - --preprocess_data
      - { inputPath: preprocess_data }
      - --input_images
      - { inputValue: input_images }
      - --inference_results
      - { outputPath: inference_results }
      - --predictions
      - { outputPath: predictions }
