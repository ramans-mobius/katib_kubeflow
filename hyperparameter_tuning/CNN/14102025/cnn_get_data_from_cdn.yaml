name: CNN Get Data Through CDN
description: Downloads preprocessed CNN dataset from CDN URL
inputs:
  - name: process_data_url
    type: String
    description: URL to fetch the preprocessed dataset from
outputs:
  - name: processed_data
    type: Dataset
  - name: config_out
    type: String

implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v19
    command:
      - sh
      - -c
      - |
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse, os, requests, json, pickle, io
        from urllib.parse import unquote

        parser = argparse.ArgumentParser()
        parser.add_argument('--process_data_url', type=str, required=True)
        parser.add_argument('--processed_data', type=str, required=True)
        parser.add_argument('--config_out', type=str, required=True)
        args = parser.parse_args()

        # Normalize URL
        url = unquote(args.process_data_url)
        print(f"ðŸ“¦ Downloading dataset from: {url}")

        # Download the pickle file
        resp = requests.get(url)
        resp.raise_for_status()
        
        # Create output directories
        os.makedirs(os.path.dirname(args.processed_data), exist_ok=True)
        os.makedirs(os.path.dirname(args.config_out), exist_ok=True)

        # Save the downloaded pickle directly
        with open(args.processed_data, "wb") as f:
            f.write(resp.content)
        print(f"âœ… Dataset saved to: {args.processed_data}")

        # Create basic config
        config = {
            "dataset_info": {
                "source": url,
                "format": "preprocessed_cnn_pickle"
            }
        }
        
        with open(args.config_out, "w") as f:
            json.dump(config, f, indent=2)
        print(f"âœ… Config saved to: {args.config_out}")

    args:
      - --process_data_url
      - { inputValue: process_data_url }
      - --processed_data
      - { outputPath: processed_data }
      - --config_out
      - { outputPath: config_out }
