name: 4 Generalized CNN Update Schema Row
description: Updates a row in a schema based on a mapping between column names and a JSON object.

inputs:
  - { name: schema_id, type: String, description: "The ID of the schema to update." }
  - { name: update_data_json, type: String, description: "JSON string containing the data to update." }
  - { name: mapping_json, type: String, description: "JSON string mapping column names to keys in update_data_json." }
  - { name: model_id, type: String, description: "The ID of the model to filter by." }
  - { name: execution_id, type: String, description: "The ID of the model to filter by." }
  - { name: tenant_id, type: string, description: "The ID of the tenant." }
  - { name: project_id, type: String, description: "The ID of the project." }
  - { name: architecture_type, type: String, description: "The architecture type." }
  - { name: multiple_rows_json, type: String, description: "JSON string containing a list of rows to create." }
  - { name: bearer_auth_token, type: string, description: "Bearer token for authentication." }
  - { name: domain, type: String, description: "The domain for the API endpoint." }
  - { name: float_keys_json, type: String, description: "JSON string of a list of keys to be converted to float."}

implementation:
  container:
    image: python:3.9-slim
    command:
      - sh
      - -c
      - |
        pip install requests
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import json
        import argparse
        import requests
        import random
        import time
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry

        parser = argparse.ArgumentParser()
        parser.add_argument('--schema_id', type=str, required=True)
        parser.add_argument('--update_data_json', type=str, required=True)
        parser.add_argument('--mapping_json', type=str, required=True)
        parser.add_argument('--model_id', type=str, required=True)
        parser.add_argument('--execution_id', type=str, required=True)
        parser.add_argument('--tenant_id', type=str, required=True)
        parser.add_argument('--project_id', type=str, required=True)
        parser.add_argument('--architecture_type', type=str, required=True)
        parser.add_argument('--multiple_rows_json', type=str, required=True)
        parser.add_argument('--bearer_auth_token', type=str, required=True)
        parser.add_argument('--domain', type=str, required=True)
        parser.add_argument('--float_keys_json', type=str, required=False)
        args = parser.parse_args()

        with open(args.bearer_auth_token, 'r') as f:
            bearer_auth_token = f.read().strip()

        with open(args.tenant_id, 'r') as f:
            tenant_id = f.read().strip()

        print(f" Input Data ")
        print(f"update_data_json: {args.update_data_json}")
        print(f"mapping_json: {args.mapping_json}")
        
        update_data = json.loads(args.update_data_json)
        mapping = json.loads(args.mapping_json)
        
        # Handle float_keys_json safely
        if args.float_keys_json and args.float_keys_json != '-1':
            float_keys = json.loads(args.float_keys_json)
        else:
            float_keys = []

        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {bearer_auth_token}'
        }

        # Enhanced retry strategy for 500 errors
        retry_strategy = Retry(
            total=5,  # Increased from 3 to 5
            status_forcelist=[408, 500, 502, 503, 504],
            allowed_methods=["HEAD", "GET", "PUT", "POST", "DELETE", "OPTIONS", "TRACE"],
            backoff_factor=2,  # Increased backoff
            backoff_jitter=0.5  # Added jitter
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        http = requests.Session()
        http.mount("https://", adapter)
        http.mount("http://", adapter)

        def get_schema_attributes(http, domain, schema_id, headers):
            endpoints = [
                f"{domain}/pi-entity-instances-service/v2.0/schemas/{schema_id}",
                f"{domain}/pi-entity-instances-service/v3.0/schemas/{schema_id}",
                f"{domain}/pi-schemas-service/v2.0/schemas/{schema_id}",
                f"{domain}/pi-schemas-service/v3.0/schemas/{schema_id}"
            ]
            
            for endpoint in endpoints:
                try:
                    print(f"Trying schema endpoint: {endpoint}")
                    response = http.get(endpoint, headers=headers, timeout=30)
                    if response.status_code == 200:
                        schema_info = response.json()
                        print(f"Successfully fetched schema from: {endpoint}")
                        
                        # Extract attributes from different possible response structures
                        attributes_map = schema_info.get('attributesMap', {})
                        if not attributes_map:
                            attributes_map = schema_info.get('properties', {})
                        if not attributes_map:
                            attributes_map = schema_info.get('attributes', {})
                        
                        # Extract required attributes
                        required_attributes = []
                        all_attributes = []
                        
                        for attr_name, attr_info in attributes_map.items():
                            all_attributes.append(attr_name)
                            # Check if attribute is required
                            if (attr_info.get('required', False) or 
                                attr_info.get('isRequired', False) or
                                attr_info.get('nullable', True) is False):
                                required_attributes.append(attr_name)
                        
                        print(f"=== SCHEMA DISCOVERY ===")
                        print(f"All attributes: {all_attributes}")
                        print(f"Required attributes: {required_attributes}")
                        print(f"========================")
                        
                        return {
                            'all_attributes': all_attributes,
                            'required_attributes': required_attributes,
                            'attributes_map': attributes_map
                        }
                    else:
                        print(f"Endpoint {endpoint} returned status: {response.status_code}")
                except Exception as e:
                    print(f"Error fetching from {endpoint}: {e}")
            
            print("WARNING: Could not fetch schema information from any endpoint")
            print("Using default required attributes")
            return {
                'all_attributes': [],
                'required_attributes': ['execution_id', 'tenant_id', 'project_id'],
                'attributes_map': {}
            }

        def extract_epoch_from_data(update_data):
            print("Extracting epoch from data...")
            print(f"Available keys in data: {list(update_data.keys())}")
            
            if isinstance(update_data, dict):
                # DEBUG: Print what we're seeing
                for key, value in update_data.items():
                    if isinstance(value, list):
                        print(f"Found list '{key}' with {len(value)} elements: {value[:3]}...")  # First 3 elements
                    else:
                        print(f"Found '{key}': {value}")
                
                # Method 1: Check for training history arrays (most reliable)
                training_arrays = ['train_loss', 'train_acc', 'val_loss', 'val_acc']
                epoch_count = None
                
                for field in training_arrays:
                    if field in update_data and isinstance(update_data[field], list):
                        current_count = len(update_data[field])
                        print(f"Found {current_count} epochs from {field} array")
                        if epoch_count is None:
                            epoch_count = current_count
                        elif current_count != epoch_count:
                            print(f"WARNING: Inconsistent array lengths: {field} has {current_count}, expected {epoch_count}")
                
                if epoch_count and epoch_count > 0:
                    # For training history, use the final epoch (0-indexed)
                    final_epoch = epoch_count - 1
                    print(f"Using final epoch from training history: {final_epoch} (0-indexed, {epoch_count} total epochs)")
                    return final_epoch
                
                # Method 2: Check for explicit epoch fields
                if 'best_epoch' in update_data:
                    best_epoch = update_data['best_epoch']
                    print(f"Found explicit best_epoch: {best_epoch}")
                    try:
                        return int(best_epoch)
                    except (ValueError, TypeError):
                        print(f"WARNING: best_epoch is not an integer: {best_epoch}")
                
                if 'epoch' in update_data:
                    epoch_val = update_data['epoch']
                    print(f"Found explicit epoch: {epoch_val}")
                    try:
                        return int(epoch_val)
                    except (ValueError, TypeError):
                        print(f"WARNING: epoch is not an integer: {epoch_val}")
                
                # Method 3: If we have best_val_loss, try to find matching epoch
                if 'best_val_loss' in update_data and 'val_loss' in update_data:
                    best_loss = update_data['best_val_loss']
                    val_losses = update_data['val_loss']
                    if isinstance(val_losses, list):
                        try:
                            # Try exact match first
                            best_epoch_index = val_losses.index(best_loss)
                            print(f"Found exact match: best_val_loss at epoch {best_epoch_index}")
                            return best_epoch_index
                        except ValueError:
                            # Find closest match
                            closest_epoch = min(range(len(val_losses)), key=lambda i: abs(val_losses[i] - best_loss))
                            print(f"Found closest epoch {closest_epoch} to best_val_loss")
                            return closest_epoch
            
            print("No epoch information found in data, defaulting to 0")
            return 0

        def validate_and_prepare_data(data, all_attributes, required_attributes, attributes_map):
            validated_data = {}
            missing_required = []
            
            # Check for required attributes and provide sensible defaults
            for req_attr in required_attributes:
                if req_attr not in data:
                    missing_required.append(req_attr)
                    # Provide intelligent defaults for common required attributes
                    if req_attr == 'epoch':
                        # Extract epoch from the input data
                        epoch_value = extract_epoch_from_data(update_data)
                        data[req_attr] = epoch_value
                        print(f"Auto-populated {req_attr} with value: {epoch_value}")
                    elif req_attr == 'execution_id' and args.execution_id != '-1':
                        data[req_attr] = args.execution_id
                        print(f"Auto-populated {req_attr} with value: {args.execution_id}")
                    elif req_attr == 'tenant_id' and args.tenant_id != '-1':
                        data[req_attr] = tenant_id
                        print(f"Auto-populated {req_attr} with value: {tenant_id}")
                    elif req_attr == 'project_id' and args.project_id != '-1':
                        data[req_attr] = args.project_id
                        print(f"Auto-populated {req_attr} with value: {args.project_id}")
                    else:
                        print(f"WARNING: No default available for required attribute: {req_attr}")
            
            # Filter and validate attributes - only include attributes that exist in schema
            for key, value in data.items():
                if not all_attributes or key in all_attributes:  # Include if no schema info or if known
                    # Convert data types based on schema
                    attr_info = attributes_map.get(key, {})
                    attr_type = attr_info.get('type', 'string')
                    if isinstance(attr_type, dict):
                        attr_type = attr_type.get('type', 'string')
                    
                    if attr_type in ['float', 'number'] and value is not None:
                        try:
                            validated_data[key] = float(value)
                        except (ValueError, TypeError):
                            validated_data[key] = str(value)
                            print(f"WARNING: Could not convert {key} to {attr_type}, using string")
                    elif attr_type in ['integer', 'long', 'int'] and value is not None:
                        try:
                            validated_data[key] = int(float(value))
                        except (ValueError, TypeError):
                            validated_data[key] = str(value)
                            print(f"WARNING: Could not convert {key} to {attr_type}, using string")
                    else:
                        validated_data[key] = value
                else:
                    print(f"WARNING: Attribute '{key}' not found in schema, skipping")
            
            if missing_required:
                print(f"Missing required attributes that were auto-populated: {missing_required}")
            
            return validated_data

        def make_request_with_circuit_breaker(http, method, url, headers, data=None, max_retries=3):
            for attempt in range(max_retries):
                try:
                    if method.upper() == 'POST':
                        response = http.post(url, headers=headers, data=json.dumps(data), timeout=60)
                    elif method.upper() == 'PATCH':
                        response = http.patch(url, headers=headers, data=json.dumps(data), timeout=60)
                    elif method.upper() == 'GET':
                        response = http.get(url, headers=headers, timeout=60)
                    else:
                        raise ValueError(f"Unsupported method: {method}")
                    
                    response.raise_for_status()
                    return response
                    
                except requests.exceptions.RequestException as e:
                    if attempt == max_retries - 1:
                        print(f"Final attempt failed after {max_retries} retries")
                        raise e
                    
                    wait_time = (2 ** attempt) + (random.random() * 0.1)
                    print(f"Request failed (attempt {attempt + 1}/{max_retries}), retrying in {wait_time:.2f}s... Error: {e}")
                    time.sleep(wait_time)

        # Get schema information dynamically
        schema_info = get_schema_attributes(http, args.domain, args.schema_id, headers)
        all_attributes = schema_info['all_attributes']
        required_attributes = schema_info['required_attributes']
        attributes_map = schema_info['attributes_map']

        if args.multiple_rows_json != '-1':
            rows_to_create = json.loads(args.multiple_rows_json)
            validated_rows = []
            
            for row in rows_to_create:
                # Add common fields only if they exist in schema
                if args.tenant_id != '-1' and 'tenant_id' in all_attributes:
                    row['tenant_id'] = tenant_id
                if args.project_id != '-1' and 'project_id' in all_attributes:
                    row['project_id'] = args.project_id
                if args.architecture_type != '-1' and 'architecture_type' in all_attributes:
                    row['architecture_type'] = args.architecture_type
                if 'execution_id' not in row and args.execution_id != '-1' and 'execution_id' in all_attributes:
                    row['execution_id'] = args.execution_id
                if args.model_id != '-1' and 'model_id' in all_attributes:
                    row['model_id'] = args.model_id
                
                # Validate and prepare data
                validated_row = validate_and_prepare_data(row, all_attributes, required_attributes, attributes_map)
                validated_rows.append(validated_row)
            
            create_url = f"{args.domain}/pi-entity-instances-service/v2.0/schemas/{args.schema_id}/instances"
            create_payload = {"data": validated_rows}
            
            print(f" Creating Multiple Rows ")
            print(f"Request URL: POST {create_url}")
            print(f"Request Headers: {json.dumps(headers)}")
            print(f"Request Payload: {json.dumps(create_payload, indent=2)}")

            try:
                response = make_request_with_circuit_breaker(http, 'POST', create_url, headers, create_payload, max_retries=3)
                print("Successfully created multiple model instances.")
                print(f"Response: {response.json()}")
            except requests.exceptions.RequestException as e:
                print(f"Error creating multiple model instances: {e}")
                print(f"Failed Request Payload: {json.dumps(create_payload, indent=2)}")
                if e.response:
                    print(f"Response Status Code: {e.response.status_code}")
                    print(f"Response Content: {e.response.text}")
                exit(1)
        else:
            # Check if execution_id exists
            check_url = f"{args.domain}/pi-entity-instances-service/v3.0/schemas/{args.schema_id}/instances/list"
            check_payload = {
                "dbType": "TIDB",
                "ownedOnly": True,
                "filter": {
                    "execution_id": args.execution_id
                }
            }
            
            print(f" Checking for Existing Row with execution_id: {args.execution_id} ")
            print(f"Request URL: POST {check_url}")
            print(f"Request Headers: {json.dumps(headers)}")
            print(f"Request Payload: {json.dumps(check_payload, indent=2)}")

            try:
                response = make_request_with_circuit_breaker(http, 'POST', check_url, headers, check_payload, max_retries=3)
                response_data = response.json()
                
                if response_data.get("content"):
                    print(f" Instance Found: Updating Row ")
                    patch_requests = []
                    for column, keys in mapping.items():
                        value_to_patch = None
                        if isinstance(keys, list):
                            value_to_patch = {key: update_data.get(key) for key in keys if key in update_data}
                        else:
                            if keys in update_data:
                                value = update_data.get(keys)
                                if keys in float_keys:
                                    try:
                                        value_to_patch = float(value)
                                    except (ValueError, TypeError):
                                        value_to_patch = str(value)
                                else:
                                    value_to_patch = str(value)

                        if value_to_patch is not None and column in all_attributes:
                            patch_requests.append({
                                "operation": "REPLACE",
                                "path": column,
                                "value": value_to_patch
                            })
                        elif value_to_patch is not None:
                            print(f"WARNING: Column '{column}' not found in schema, skipping update")

                    update_url = f"{args.domain}/pi-entity-instances-service/v2.0/schemas/{args.schema_id}/instances"
                    update_payload = {
                        "dbType": "TIDB",
                        "conditionalFilter": {
                            "conditions": [
                                {
                                    "field": "execution_id",
                                    "operator": "EQUAL",
                                    "value": args.execution_id
                                }
                            ]
                        },
                        "partialUpdateRequests": [
                            {
                                "patch": patch_requests
                            }
                        ]
                    }
                    
                    print(f"Request URL: PATCH {update_url}")
                    print(f"Request Headers: {json.dumps(headers)}")
                    print(f"Request Payload: {json.dumps(update_payload, indent=2)}")
                    
                    response = make_request_with_circuit_breaker(http, 'PATCH', update_url, headers, update_payload, max_retries=3)
                    print("Successfully updated the model instance.")
                else:
                    print(f" No Instance Found: Creating New Row ")
                    creation_data = {}
                    for column, keys in mapping.items():
                        value_to_add = None
                        if isinstance(keys, list):
                            value_to_add = {key: update_data.get(key) for key in keys if key in update_data}
                        else:
                            if keys in update_data:
                                value = update_data.get(keys)
                                if keys in float_keys:
                                    try:
                                        value_to_add = float(value)
                                    except (ValueError, TypeError):
                                        value_to_add = str(value)
                                else:
                                    value_to_add = str(value)

                        if value_to_add is not None and column in all_attributes:
                            creation_data[column] = value_to_add
                        elif value_to_add is not None:
                            print(f"WARNING: Column '{column}' not found in schema, skipping")
                    
                    # Add common fields only if they exist in schema
                    if 'execution_id' in all_attributes:
                        creation_data['execution_id'] = args.execution_id
                    if args.model_id != '-1' and 'model_id' in all_attributes:
                        creation_data['model_id'] = args.model_id
                    if args.tenant_id != '-1' and 'tenant_id' in all_attributes:
                        creation_data['tenant_id'] = tenant_id
                    if args.project_id != '-1' and 'project_id' in all_attributes:
                        creation_data['project_id'] = args.project_id
                    if args.architecture_type != '-1' and 'architecture_type' in all_attributes:
                        creation_data['architecture_type'] = args.architecture_type

                    # Validate and prepare data for schema
                    creation_data = validate_and_prepare_data(creation_data, all_attributes, required_attributes, attributes_map)

                    create_url = f"{args.domain}/pi-entity-instances-service/v2.0/schemas/{args.schema_id}/instances"
                    create_payload = {
                        "data": [creation_data]
                    }

                    print(f"Request URL: POST {create_url}")
                    print(f"Request Headers: {json.dumps(headers)}")
                    print(f"Request Payload: {json.dumps(create_payload, indent=2)}")
                    
                    response = make_request_with_circuit_breaker(http, 'POST', create_url, headers, create_payload, max_retries=3)
                    if response.status_code >= 400:
                        print(f"Error: {response.status_code} {response.reason}")
                        print(f"Response Content: {response.text}")
                    response.raise_for_status()
                    print("Successfully created a new model instance.")
                    
                print(f"Response: {response.json()}")

            except requests.exceptions.RequestException as e:
                print(f"Error: {e}")
                if e.response is not None:
                    print(f"Response Status Code: {e.response.status_code}")
                    print(f"Response Content: {e.response.text}")
                exit(1)

    args:
      - --schema_id
      - {inputValue: schema_id}
      - --update_data_json
      - {inputValue: update_data_json}
      - --mapping_json
      - {inputValue: mapping_json}
      - --model_id
      - {inputValue: model_id}
      - --execution_id
      - {inputValue: execution_id}
      - --tenant_id
      - {inputPath: tenant_id}
      - --project_id
      - {inputValue: project_id}
      - --architecture_type
      - {inputValue: architecture_type}
      - --multiple_rows_json
      - {inputValue: multiple_rows_json}
      - --bearer_auth_token
      - {inputPath: bearer_auth_token}
      - --domain
      - {inputValue: domain}
      - --float_keys_json
      - {inputValue: float_keys_json}
