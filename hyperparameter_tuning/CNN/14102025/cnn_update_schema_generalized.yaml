name: T Generalized CNN Update Schema Row 
description: Updates a row in a schema based on a mapping between column names and a JSON object.

inputs:
  - { name: schema_id, type: String, description: "The ID of the schema to update." }
  - { name: update_data_json, type: String, description: "JSON string containing the data to update." }
  - { name: mapping_json, type: String, description: "JSON string mapping column names to keys in update_data_json." }
  - { name: model_id, type: String, description: "The ID of the model to filter by." }
  - { name: execution_id, type: String, description: "The ID of the model to filter by." }
  - { name: tenant_id, type: string, description: "The ID of the tenant." }
  - { name: project_id, type: String, description: "The ID of the project." }
  - { name: architecture_type, type: String, description: "The architecture type." }
  - { name: multiple_rows_json, type: String, description: "JSON string containing a list of rows to create." }
  - { name: bearer_auth_token, type: string, description: "Bearer token for authentication." }
  - { name: domain, type: String, description: "The domain for the API endpoint." }
  - { name: float_keys_json, type: String, description: "JSON string of a list of keys to be converted to float."}

implementation:
  container:
    image: python:3.9-slim
    command:
      - sh
      - -c
      - |
        pip install requests
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import json
        import argparse
        import requests
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry

        parser = argparse.ArgumentParser()
        parser.add_argument('--schema_id', type=str, required=True)
        parser.add_argument('--update_data_json', type=str, required=True)
        parser.add_argument('--mapping_json', type=str, required=True)
        parser.add_argument('--model_id', type=str, required=True)
        parser.add_argument('--execution_id', type=str, required=True)
        parser.add_argument('--tenant_id', type=str, required=True)
        parser.add_argument('--project_id', type=str, required=True)
        parser.add_argument('--architecture_type', type=str, required=True)
        parser.add_argument('--multiple_rows_json', type=str, required=True)
        parser.add_argument('--bearer_auth_token', type=str, required=True)
        parser.add_argument('--domain', type=str, required=True)
        parser.add_argument('--float_keys_json', type=str, required=False)
        args = parser.parse_args()

        with open(args.bearer_auth_token, 'r') as f:
            bearer_auth_token = f.read().strip()

        with open(args.tenant_id, 'r') as f:
            tenant_id = f.read().strip()

        print(f" Input Data ")
        print(f"update_data_json: {args.update_data_json}")
        print(f"mapping_json: {args.mapping_json}")
        
        update_data = json.loads(args.update_data_json)
        mapping = json.loads(args.mapping_json)
        
        # Handle float_keys_json safely
        if args.float_keys_json and args.float_keys_json != '-1':
            float_keys = json.loads(args.float_keys_json)
        else:
            float_keys = []

        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {bearer_auth_token}'
        }

        retry_strategy = Retry(
            total=3,
            status_forcelist=[408, 500, 502, 503, 504],
            allowed_methods=["HEAD", "GET", "PUT", "POST", "DELETE", "OPTIONS", "TRACE"],
            backoff_factor=1
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        http = requests.Session()
        http.mount("https://", adapter)
        http.mount("http://", adapter)

        # Discover schema structure
        def get_schema_info(http, domain, schema_id, headers):
            try:
                schema_url = f"{domain}/pi-entity-instances-service/v2.0/schemas/{schema_id}"
                response = http.get(schema_url, headers=headers, timeout=30)
                if response.status_code == 200:
                    schema_info = response.json()
                    attributes_map = schema_info.get('attributesMap', {})
                    
                    # Extract required attributes
                    required_attributes = []
                    all_attributes = []
                    for attr_name, attr_info in attributes_map.items():
                        all_attributes.append(attr_name)
                        if attr_info.get('required', False):
                            required_attributes.append(attr_name)
                    
                    print(f"=== SCHEMA DISCOVERY ===")
                    print(f"All attributes: {all_attributes}")
                    print(f"Required attributes: {required_attributes}")
                    print(f"========================")
                    
                    return {
                        'all_attributes': all_attributes,
                        'required_attributes': required_attributes,
                        'attributes_map': attributes_map
                    }
                else:
                    print(f"Schema discovery failed with status: {response.status_code}")
            except Exception as e:
                print(f"Could not fetch schema info: {e}")
            
            # Return default if schema discovery fails
            return {
                'all_attributes': [],
                'required_attributes': ['execution_id', 'tenant_id', 'project_id'],
                'attributes_map': {}
            }

        # Get schema information
        schema_info = get_schema_info(http, args.domain, args.schema_id, headers)
        all_attributes = schema_info['all_attributes']
        required_attributes = schema_info['required_attributes']
        attributes_map = schema_info['attributes_map']

        def extract_epoch_from_data(update_data):
            """Extract epoch information from the input data dynamically"""
            # Check if we have training history arrays that can indicate epoch count
            if isinstance(update_data, dict):
                # Look for array fields that might contain epoch data
                array_fields = ['train_loss', 'train_acc', 'val_loss', 'val_acc']
                for field in array_fields:
                    if field in update_data and isinstance(update_data[field], list):
                        epoch_count = len(update_data[field])
                        print(f"Found {epoch_count} epochs from {field} array")
                        return epoch_count - 1  # Return last epoch index
                
                # Check for best_epoch field
                if 'best_epoch' in update_data:
                    return update_data['best_epoch']
                
                # Check for epoch field directly
                if 'epoch' in update_data:
                    return update_data['epoch']
            
            # Default to 0 if no epoch information found
            return 0

        def validate_and_prepare_data(data, all_attributes, required_attributes, attributes_map):
            validated_data = {}
            missing_required = []
            
            # Check for required attributes and provide sensible defaults
            for req_attr in required_attributes:
                if req_attr not in data:
                    missing_required.append(req_attr)
                    # Provide intelligent defaults for common required attributes
                    if req_attr == 'epoch':
                        # Extract epoch from the input data
                        epoch_value = extract_epoch_from_data(update_data)
                        data[req_attr] = epoch_value
                        print(f"Auto-populated {req_attr} with value: {epoch_value}")
                    elif req_attr == 'execution_id' and args.execution_id != '-1':
                        data[req_attr] = args.execution_id
                        print(f"Auto-populated {req_attr} with value: {args.execution_id}")
                    elif req_attr == 'tenant_id' and args.tenant_id != '-1':
                        data[req_attr] = tenant_id
                        print(f"Auto-populated {req_attr} with value: {tenant_id}")
                    elif req_attr == 'project_id' and args.project_id != '-1':
                        data[req_attr] = args.project_id
                        print(f"Auto-populated {req_attr} with value: {args.project_id}")
                    else:
                        print(f"WARNING: No default available for required attribute: {req_attr}")
            
            # Filter and validate attributes - only include attributes that exist in schema
            for key, value in data.items():
                if not all_attributes or key in all_attributes:  # Include if no schema info or if known
                    # Convert data types based on schema
                    attr_info = attributes_map.get(key, {})
                    attr_type = attr_info.get('type', {}).get('type', 'string')
                    
                    if attr_type in ['float', 'integer', 'long'] and value is not None:
                        try:
                            if attr_type == 'float':
                                validated_data[key] = float(value)
                            elif attr_type in ['integer', 'long']:
                                validated_data[key] = int(float(value))  # Handle both int and float strings
                            else:
                                validated_data[key] = value
                        except (ValueError, TypeError):
                            validated_data[key] = str(value)
                            print(f"WARNING: Could not convert {key} to {attr_type}, using string")
                    else:
                        validated_data[key] = value
                else:
                    print(f"WARNING: Attribute '{key}' not found in schema, skipping")
            
            if missing_required:
                print(f"Missing required attributes that were auto-populated: {missing_required}")
            
            return validated_data

        if args.multiple_rows_json != '-1':
            rows_to_create = json.loads(args.multiple_rows_json)
            validated_rows = []
            
            for row in rows_to_create:
                # Add common fields only if they exist in schema
                if args.tenant_id != '-1' and 'tenant_id' in all_attributes:
                    row['tenant_id'] = tenant_id
                if args.project_id != '-1' and 'project_id' in all_attributes:
                    row['project_id'] = args.project_id
                if args.architecture_type != '-1' and 'architecture_type' in all_attributes:
                    row['architecture_type'] = args.architecture_type
                if 'execution_id' not in row and args.execution_id != '-1' and 'execution_id' in all_attributes:
                    row['execution_id'] = args.execution_id
                if args.model_id != '-1' and 'model_id' in all_attributes:
                    row['model_id'] = args.model_id
                
                # Validate and prepare data
                validated_row = validate_and_prepare_data(row, all_attributes, required_attributes, attributes_map)
                validated_rows.append(validated_row)
            
            create_url = f"{args.domain}/pi-entity-instances-service/v2.0/schemas/{args.schema_id}/instances"
            create_payload = {"data": validated_rows}
            
            print(f" Creating Multiple Rows ")
            print(f"Request URL: POST {create_url}")
            print(f"Request Headers: {json.dumps(headers)}")
            print(f"Request Payload: {json.dumps(create_payload, indent=2)}")

            try:
                response = http.post(create_url, headers=headers, data=json.dumps(create_payload), timeout=60)
                response.raise_for_status()
                print("Successfully created multiple model instances.")
                print(f"Response: {response.json()}")
            except requests.exceptions.RequestException as e:
                print(f"Error creating multiple model instances: {e}")
                print(f"Failed Request Payload: {json.dumps(create_payload, indent=2)}")
                if e.response:
                    print(f"Response Status Code: {e.response.status_code}")
                    print(f"Response Content: {e.response.text}")
                exit(1)
        else:
            # Check if execution_id exists
            check_url = f"{args.domain}/pi-entity-instances-service/v3.0/schemas/{args.schema_id}/instances/list"
            check_payload = {
                "dbType": "TIDB",
                "ownedOnly": True,
                "filter": {
                    "execution_id": args.execution_id
                }
            }
            
            print(f" Checking for Existing Row with execution_id: {args.execution_id} ")
            print(f"Request URL: POST {check_url}")
            print(f"Request Headers: {json.dumps(headers)}")
            print(f"Request Payload: {json.dumps(check_payload, indent=2)}")

            try:
                response = http.post(check_url, headers=headers, data=json.dumps(check_payload), timeout=60)
                response.raise_for_status()
                response_data = response.json()
                
                if response_data.get("content"):
                    print(f" Instance Found: Updating Row ")
                    patch_requests = []
                    for column, keys in mapping.items():
                        value_to_patch = None
                        if isinstance(keys, list):
                            value_to_patch = {key: update_data.get(key) for key in keys if key in update_data}
                        else:
                            if keys in update_data:
                                value = update_data.get(keys)
                                if keys in float_keys:
                                    try:
                                        value_to_patch = float(value)
                                    except (ValueError, TypeError):
                                        value_to_patch = str(value)
                                else:
                                    value_to_patch = str(value)

                        if value_to_patch is not None and column in all_attributes:
                            patch_requests.append({
                                "operation": "REPLACE",
                                "path": column,
                                "value": value_to_patch
                            })
                        elif value_to_patch is not None:
                            print(f"WARNING: Column '{column}' not found in schema, skipping update")

                    update_url = f"{args.domain}/pi-entity-instances-service/v2.0/schemas/{args.schema_id}/instances"
                    update_payload = {
                        "dbType": "TIDB",
                        "conditionalFilter": {
                            "conditions": [
                                {
                                    "field": "execution_id",
                                    "operator": "EQUAL",
                                    "value": args.execution_id
                                }
                            ]
                        },
                        "partialUpdateRequests": [
                            {
                                "patch": patch_requests
                            }
                        ]
                    }
                    
                    print(f"Request URL: PATCH {update_url}")
                    print(f"Request Headers: {json.dumps(headers)}")
                    print(f"Request Payload: {json.dumps(update_payload, indent=2)}")
                    
                    response = http.patch(update_url, headers=headers, data=json.dumps(update_payload), timeout=60)
                    response.raise_for_status()
                    print("Successfully updated the model instance.")
                else:
                    print(f" No Instance Found: Creating New Row ")
                    creation_data = {}
                    for column, keys in mapping.items():
                        value_to_add = None
                        if isinstance(keys, list):
                            value_to_add = {key: update_data.get(key) for key in keys if key in update_data}
                        else:
                            if keys in update_data:
                                value = update_data.get(keys)
                                if keys in float_keys:
                                    try:
                                        value_to_add = float(value)
                                    except (ValueError, TypeError):
                                        value_to_add = str(value)
                                else:
                                    value_to_add = str(value)

                        if value_to_add is not None and column in all_attributes:
                            creation_data[column] = value_to_add
                        elif value_to_add is not None:
                            print(f"WARNING: Column '{column}' not found in schema, skipping")
                    
                    # Add common fields only if they exist in schema
                    if 'execution_id' in all_attributes:
                        creation_data['execution_id'] = args.execution_id
                    if args.model_id != '-1' and 'model_id' in all_attributes:
                        creation_data['model_id'] = args.model_id
                    if args.tenant_id != '-1' and 'tenant_id' in all_attributes:
                        creation_data['tenant_id'] = tenant_id
                    if args.project_id != '-1' and 'project_id' in all_attributes:
                        creation_data['project_id'] = args.project_id
                    if args.architecture_type != '-1' and 'architecture_type' in all_attributes:
                        creation_data['architecture_type'] = args.architecture_type

                    # Validate and prepare data for schema
                    creation_data = validate_and_prepare_data(creation_data, all_attributes, required_attributes, attributes_map)

                    create_url = f"{args.domain}/pi-entity-instances-service/v2.0/schemas/{args.schema_id}/instances"
                    create_payload = {
                        "data": [creation_data]
                    }

                    print(f"Request URL: POST {create_url}")
                    print(f"Request Headers: {json.dumps(headers)}")
                    print(f"Request Payload: {json.dumps(create_payload, indent=2)}")
                    
                    response = http.post(create_url, headers=headers, data=json.dumps(create_payload), timeout=60)
                    if response.status_code >= 400:
                        print(f"Error: {response.status_code} {response.reason}")
                        print(f"Response Content: {response.text}")
                    response.raise_for_status()
                    print("Successfully created a new model instance.")
                    
                print(f"Response: {response.json()}")

            except requests.exceptions.RequestException as e:
                print(f"Error: {e}")
                if e.response is not None:
                    print(f"Response Status Code: {e.response.status_code}")
                    print(f"Response Content: {e.response.text}")
                exit(1)

    args:
      - --schema_id
      - {inputValue: schema_id}
      - --update_data_json
      - {inputValue: update_data_json}
      - --mapping_json
      - {inputValue: mapping_json}
      - --model_id
      - {inputValue: model_id}
      - --execution_id
      - {inputValue: execution_id}
      - --tenant_id
      - {inputPath: tenant_id}
      - --project_id
      - {inputValue: project_id}
      - --architecture_type
      - {inputValue: architecture_type}
      - --multiple_rows_json
      - {inputValue: multiple_rows_json}
      - --bearer_auth_token
      - {inputPath: bearer_auth_token}
      - --domain
      - {inputValue: domain}
      - --float_keys_json
      - {inputValue: float_keys_json}
