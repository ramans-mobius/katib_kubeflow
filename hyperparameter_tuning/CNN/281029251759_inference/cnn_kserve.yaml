name: 2 Serve a model with KServe
description: Serve Models using KServe for PyTorch CNN
inputs:
  - name: Action
    type: String
    default: 'create'
  - name: Model Name
    type: String
    default: 'cnn-classifier'
  - name: Model URI
    type: String
    default: ''
  - name: Canary Traffic Percent
    type: String
    default: '100'
  - name: Namespace
    type: String
    default: 'kserve-test'
  - name: Framework
    type: String
    default: 'pytorch'
  - name: Runtime Version
    type: String
    default: 'latest'
  - name: Resource Requests
    type: String
    default: 'cpu=1,memory=2Gi'  # ← Simple string instead of JSON
  - name: Resource Limits
    type: String
    default: 'cpu=2,memory=4Gi'  # ← Simple string instead of JSON
  - name: Custom Model Spec
    type: String
    default: '{}'
  - name: Autoscaling Target
    type: String
    default: '50'
  - name: Service Account
    type: String
    default: 'sa'
  - name: Enable Istio Sidecar
    type: Bool
    default: 'True'
  - name: InferenceService YAML
    type: String
    default: '{}'
  - name: Watch Timeout
    type: String
    default: '1200'
  - name: Min Replicas
    type: String
    default: '1'
  - name: Max Replicas
    type: String
    default: '3'
  - name: Request Timeout
    type: String
    default: '300'
  - name: Enable ISVC Status
    type: Bool
    default: 'True'

outputs:
  - name: InferenceService Status
    type: String

implementation:
  container:
    image: nikhilv215/kserve:kserve_component-v6
    command: ['python']
    args:
      - -u
      - kservedeployer.py
      - --action
      - {inputValue: Action}
      - --model-name
      - {inputValue: Model Name}
      - --model-uri
      - {inputValue: Model URI}
      - --canary-traffic-percent
      - {inputValue: Canary Traffic Percent}
      - --namespace
      - {inputValue: Namespace}
      - --framework
      - {inputValue: Framework}
      - --runtime-version
      - {inputValue: Runtime Version}
      - --resource-requests
      - {inputValue: Resource Requests}
      - --resource-limits
      - {inputValue: Resource Limits}
      - --custom-model-spec
      - {inputValue: Custom Model Spec}
      - --autoscaling-target
      - {inputValue: Autoscaling Target}
      - --service-account
      - {inputValue: Service Account}
      - --enable-istio-sidecar
      - {inputValue: Enable Istio Sidecar}
      - --output-path
      - {outputPath: InferenceService Status}
      - --inferenceservice-yaml
      - {inputValue: InferenceService YAML}
      - --watch-timeout
      - {inputValue: Watch Timeout}
      - --min-replicas
      - {inputValue: Min Replicas}
      - --max-replicas
      - {inputValue: Max Replicas}
      - --request-timeout
      - {inputValue: Request Timeout}
      - --enable-isvc-status
      - {inputValue: Enable ISVC Status}
