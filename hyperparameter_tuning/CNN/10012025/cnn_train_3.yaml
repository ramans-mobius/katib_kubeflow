name: 9 CNN Model Trainer
description: Trains CNN model on preprocessed data
inputs:
  - name: model_path
    type: String
    description: Path to built model file
  - name: processed_data_path
    type: String
    description: Path to preprocessed data file
  - name: model_config
    type: String
    description: Complete model configuration with training parameters
outputs:
  - name: trained_model_path
    type: String
    description: Path to trained model file
  - name: training_history
    type: String
    description: JSON string with training history and metrics
  - name: final_accuracy
    type: String
    description: Final validation accuracy

implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v19
    command:
    - python3
    - -u
    - -c
    - |
      import os
      import sys
      import json
      import torch
      import torch.nn as nn
      import torch.optim as optim
      from pathlib import Path
      import pickle
      import base64
      
      print("CNN MODEL TRAINER STARTED")
      print("Command line args received: " + str(sys.argv))
      
      import argparse
      parser = argparse.ArgumentParser()
      parser.add_argument('--model_path', type=str, required=True)
      parser.add_argument('--processed_data_path', type=str, required=True)
      parser.add_argument('--model_config', type=str, required=True)
      parser.add_argument('--trained_model_path', type=str, required=True)
      parser.add_argument('--training_history', type=str, required=True)
      parser.add_argument('--final_accuracy', type=str, required=True)
      args = parser.parse_args()
      
      print("Model path input file: " + args.model_path)
      print("Data path input file: " + args.processed_data_path)
      print("Config input file: " + args.model_config)
      
      print("DEBUGGING INPUT FILES")
      
      if os.path.exists(args.model_path):
          with open(args.model_path, 'r') as f:
              model_file_content = f.read().strip()
          print("Model path file exists. Content: " + model_file_content)
          model_file_path = model_file_content
      else:
          print("ERROR: Model path file does not exist: " + args.model_path)
          print("Current directory contents:")
          for item in os.listdir('.'):
              print("  " + item)
          sys.exit(1)
      
      if os.path.exists(args.processed_data_path):
          with open(args.processed_data_path, 'r') as f:
              data_file_content = f.read().strip()
          print("Data path file exists. Content: " + data_file_content)
          data_file_path = data_file_content
      else:
          print("ERROR: Data path file does not exist: " + args.processed_data_path)
          sys.exit(1)
      
      if os.path.exists(args.model_config):
          with open(args.model_config, 'r') as f:
              model_config_content = f.read().strip()
          
          print("Config file exists. Size: " + str(len(model_config_content)) + " characters")
          print("Config file content (first 500 chars): " + model_config_content[:500])
          
          config_bytes = model_config_content.encode('utf-8')
          config_b64 = base64.b64encode(config_bytes).decode('utf-8')
          print("Config content (Base64): " + config_b64)
          
          try:
              if model_config_content:
                  model_config = json.loads(model_config_content)
                  print("SUCCESS: Parsed model config with keys: " + str(list(model_config.keys())))
                  
                  print("Config structure:")
                  for key, value in model_config.items():
                      if isinstance(value, dict):
                          print("  " + key + ": (dict with keys: " + str(list(value.keys())) + ")")
                      else:
                          print("  " + key + ": " + str(value))
              else:
                  print("ERROR: Config file is EMPTY")
                  model_config = {}
          except json.JSONDecodeError as e:
              print("ERROR: Failed to parse config as JSON: " + str(e))
              print("Raw config content that failed: " + model_config_content)
              sys.exit(1)
      else:
          print("ERROR: Config file does not exist: " + args.model_config)
          sys.exit(1)
      
      print("EXTRACTING TRAINING PARAMETERS")
      
      training_config = model_config.get('training', {})
      model_config_section = model_config.get('model', {})
      
      epochs = training_config.get('epochs', 2)
      learning_rate = training_config.get('learning_rate', 0.001)
      patience = training_config.get('patience', 2)
      batch_size = training_config.get('batch_size', 32)
      
      print("Training Parameters:")
      print("  - Epochs: " + str(epochs))
      print("  - Learning rate: " + str(learning_rate))
      print("  - Patience: " + str(patience))
      print("  - Batch size: " + str(batch_size))
      
      try:
          print("LOADING MODEL AND DATA")
          
          print("Loading model from: " + model_file_path)
          with open(model_file_path, 'rb') as f:
              model = pickle.load(f)
          
          device = model.device
          print("Model loaded successfully. Device: " + str(device))
          print("Model type: " + str(type(model)))
          
          print("Loading data from: " + data_file_path)
          with open(data_file_path, 'rb') as f:
              processed_data = pickle.load(f)
          
          print("Data keys: " + str(list(processed_data.keys())))
          
          train_loader = processed_data.get('train_loader')
          val_loader = processed_data.get('val_loader')
          data_info = processed_data.get('data_info', {})
          
          if train_loader is None:
              print("ERROR: train_loader is None in processed data")
              sys.exit(1)
              
          print("Training samples: " + str(len(train_loader.dataset)))
          if val_loader:
              print("Validation samples: " + str(len(val_loader.dataset)))
          else:
              print("No validation loader found, will split training data")
          
          optimizer = optim.Adam(model.parameters(), lr=learning_rate)
          criterion = nn.CrossEntropyLoss()
          
          print("STARTING TRAINING")
          training_history = []
          best_val_acc = 0.0
          patience_counter = 0
          best_model_state = None
          
          for epoch in range(epochs):
              model.train()
              train_loss = 0.0
              train_correct = 0
              train_total = 0
              
              for batch_idx, (data, target) in enumerate(train_loader):
                  data, target = data.to(device), target.to(device)
                  
                  optimizer.zero_grad()
                  output = model(data)
                  loss = criterion(output, target)
                  loss.backward()
                  optimizer.step()
                  
                  train_loss += loss.item()
                  _, predicted = output.max(1)
                  train_total += target.size(0)
                  train_correct += predicted.eq(target).sum().item()
              
              train_acc = 100.0 * train_correct / train_total
              avg_train_loss = train_loss / len(train_loader)
              
              val_acc = 0.0
              avg_val_loss = 0.0
              
              if val_loader:
                  model.eval()
                  val_loss = 0.0
                  val_correct = 0
                  val_total = 0
                  
                  with torch.no_grad():
                      for data, target in val_loader:
                          data, target = data.to(device), target.to(device)
                          output = model(data)
                          loss = criterion(output, target)
                          
                          val_loss += loss.item()
                          _, predicted = output.max(1)
                          val_total += target.size(0)
                          val_correct += predicted.eq(target).sum().item()
                  
                  val_acc = 100.0 * val_correct / val_total
                  avg_val_loss = val_loss / len(val_loader)
              
              epoch_info = {
                  'epoch': epoch + 1,
                  'train_loss': avg_train_loss,
                  'train_accuracy': train_acc,
                  'val_loss': avg_val_loss,
                  'val_accuracy': val_acc
              }
              training_history.append(epoch_info)
              
              print("Epoch " + str(epoch+1) + "/" + str(epochs) + ": Train Loss: " + str(avg_train_loss) + ", Acc: " + str(train_acc) + "% | Val Loss: " + str(avg_val_loss) + ", Acc: " + str(val_acc) + "%")
              
              if val_acc > best_val_acc:
                  best_val_acc = val_acc
                  patience_counter = 0
                  best_model_state = model.state_dict().copy()
              else:
                  patience_counter += 1
                  
              if patience_counter >= patience:
                  print("Early stopping at epoch " + str(epoch+1))
                  break
          
          trained_model_file_path = "/tmp/trained_model.pth"
          torch.save({
              'model_state_dict': model.state_dict(),
              'training_history': training_history,
              'final_val_accuracy': best_val_acc
          }, trained_model_file_path)
          
          os.makedirs(os.path.dirname(args.trained_model_path), exist_ok=True)
          os.makedirs(os.path.dirname(args.training_history), exist_ok=True)
          os.makedirs(os.path.dirname(args.final_accuracy), exist_ok=True)
          
          with open(args.trained_model_path, 'w') as f:
              f.write(trained_model_file_path)
          with open(args.training_history, 'w') as f:
              json.dump(training_history, f, indent=2)
          with open(args.final_accuracy, 'w') as f:
              f.write("{:.2f}".format(best_val_acc))
          
          print("Training completed successfully!")
          print("Best validation accuracy: " + str(best_val_acc) + "%")
          print("Output files written successfully")
          
      except Exception as e:
          print("Training failed: " + str(e))
          import traceback
          traceback.print_exc()
          sys.exit(1)
    
    args:
    - --model_path
    - {inputValue: model_path}
    - --processed_data_path
    - {inputValue: processed_data_path}
    - --model_config
    - {inputValue: model_config}
    - --trained_model_path
    - {outputPath: trained_model_path}
    - --training_history
    - {outputPath: training_history}
    - --final_accuracy
    - {outputPath: final_accuracy}
