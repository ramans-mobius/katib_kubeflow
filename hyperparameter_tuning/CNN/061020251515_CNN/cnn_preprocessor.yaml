name: universal_cnn_preprocessor
description: Universal preprocessing for any dataset structure with automatic detection

inputs:
  - name: data_info
    type: dict
    description: Data information from data loader
  - name: dataset_name
    type: string
    description: Original dataset name for torchvision datasets
  - name: batch_size
    type: integer
    description: Batch size for data loaders
    default: 64
  - name: validation_split
    type: float
    description: Fraction of data to use for validation
    default: 0.2
  - name: input_size
    type: list
    description: Input image size as [height, width]
    default: [224, 224]

outputs:
  - name: processed_data_path
    type: string
    description: Path to preprocessed data with loaders
  - name: preprocessing_info
    type: dict
    description: Information about preprocessing results including input_shape

implementation:
  language: python
  source: |
    import os
    import pickle
    from pathlib import Path
    import torch
    from torch.utils.data import DataLoader, random_split
    import torchvision.transforms as transforms
    import torchvision
    from PIL import Image
    import numpy as np

    def get_universal_transforms(input_size=(224, 224), is_training=False):
        mean = [0.485, 0.456, 0.406]
        std = [0.229, 0.224, 0.225]
        
        transform_list = []
        
        if is_training:
            transform_list.extend([
                transforms.RandomHorizontalFlip(p=0.5),
                transforms.RandomRotation(degrees=15),
                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
                transforms.RandomResizedCrop(input_size, scale=(0.8, 1.0))
            ])
        else:
            transform_list.extend([
                transforms.Resize(input_size),
                transforms.CenterCrop(input_size)
            ])
        
        transform_list.extend([
            transforms.ToTensor(),
            transforms.Normalize(mean, std)
        ])
        
        return transforms.Compose(transform_list)

    def detect_dataset_structure(data_path):
        if os.path.exists(os.path.join(data_path, 'train')) and os.path.exists(os.path.join(data_path, 'test')):
            return 'imagefolder_split'
        elif os.path.exists(os.path.join(data_path, 'train')):
            return 'imagefolder_train_only'
        elif any(os.path.isdir(os.path.join(data_path, d)) for d in os.listdir(data_path)):
            return 'imagefolder_flat'
        elif any(f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')) for f in os.listdir(data_path)):
            return 'single_directory'
        else:
            return 'unknown'

    def get_num_classes_from_dataset(dataset):
        try:
            if hasattr(dataset, 'targets'):
                targets = dataset.targets
                if isinstance(targets, (list, np.ndarray)):
                    unique_labels = np.unique(targets)
                    return len(unique_labels)
            
            if hasattr(dataset, 'classes'):
                return len(dataset.classes)
            
            if hasattr(dataset, 'class_to_idx'):
                return len(dataset.class_to_idx)
            
            all_labels = set()
            sample_size = min(1000, len(dataset))
            for i in range(sample_size):
                try:
                    _, label = dataset[i]
                    all_labels.add(label)
                except:
                    continue
            
            if all_labels:
                return len(all_labels)
            
            return 2
            
        except Exception as e:
            print(f"Warning: Error detecting classes: {e}, defaulting to 2")
            return 2

    def load_torchvision_dataset(dataset_name, data_path, is_training=True, input_size=(224, 224)):
        dataset_map = {
            'cifar10': torchvision.datasets.CIFAR10,
            'cifar100': torchvision.datasets.CIFAR100,
            'mnist': torchvision.datasets.MNIST,
            'fashionmnist': torchvision.datasets.FashionMNIST,
            'kmnist': torchvision.datasets.KMNIST,
        }
        
        dataset_name_lower = dataset_name.lower()
        
        if dataset_name_lower in dataset_map:
            dataset_class = dataset_map[dataset_name_lower]
            
            if dataset_name_lower in ['mnist', 'fashionmnist', 'kmnist']:
                transform_list = []
                if is_training:
                    transform_list.extend([
                        transforms.RandomHorizontalFlip(p=0.5),
                        transforms.RandomRotation(degrees=15),
                    ])
                transform_list.extend([
                    transforms.Resize(input_size),
                    transforms.Grayscale(3),
                    transforms.ToTensor(),
                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
                ])
                transform = transforms.Compose(transform_list)
            else:
                transform_list = []
                if is_training:
                    transform_list.extend([
                        transforms.RandomHorizontalFlip(p=0.5),
                        transforms.RandomCrop(32, padding=4),
                    ])
                transform_list.extend([
                    transforms.Resize(input_size),
                    transforms.ToTensor(),
                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
                ])
                transform = transforms.Compose(transform_list)
            
            try:
                dataset = dataset_class(
                    root=data_path, 
                    train=is_training, 
                    download=False,
                    transform=transform
                )
                return dataset
            except Exception as e:
                print(f"Error loading {dataset_name}: {e}")
                raise
        
        return None

    def load_any_dataset(data_path, dataset_name=None, is_training=True, input_size=(224, 224)):
        if dataset_name:
            torchvision_dataset = load_torchvision_dataset(dataset_name, data_path, is_training, input_size)
            if torchvision_dataset is not None:
                return torchvision_dataset
        
        structure = detect_dataset_structure(data_path)
        transform = get_universal_transforms(input_size, is_training=is_training)
        
        if structure == 'imagefolder_split':
            split_dir = 'train' if is_training else 'test'
            dataset_path = os.path.join(data_path, split_dir)
            return torchvision.datasets.ImageFolder(root=dataset_path, transform=transform)
        
        elif structure == 'imagefolder_train_only':
            if is_training:
                return torchvision.datasets.ImageFolder(
                    root=os.path.join(data_path, 'train'), 
                    transform=transform
                )
            else:
                return torchvision.datasets.ImageFolder(
                    root=os.path.join(data_path, 'train'), 
                    transform=get_universal_transforms(input_size, is_training=False)
                )
        
        elif structure == 'imagefolder_flat':
            return torchvision.datasets.ImageFolder(root=data_path, transform=transform)
        
        elif structure == 'single_directory':
            class SingleClassDataset(torch.utils.data.Dataset):
                def __init__(self, data_path, transform=None):
                    self.data_path = data_path
                    self.transform = transform
                    self.image_files = [f for f in os.listdir(data_path) 
                                      if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]
                
                def __len__(self):
                    return len(self.image_files)
                
                def __getitem__(self, idx):
                    img_path = os.path.join(self.data_path, self.image_files[idx])
                    image = Image.open(img_path).convert('RGB')
                    if self.transform:
                        image = self.transform(image)
                    return image, 0
            
            return SingleClassDataset(data_path, transform)
        
        else:
            raise ValueError(f"Unsupported dataset structure: {structure}")

    def execute(inputs):
        data_info = inputs["data_info"]
        dataset_name = inputs["dataset_name"]
        batch_size = inputs["batch_size"]
        validation_split = inputs["validation_split"]
        input_size = tuple(inputs["input_size"])
        
        data_path = data_info['data_path']
        
        print(f"=== UNIVERSAL DATASET PREPROCESSING ===")
        print(f"Dataset: {dataset_name}")
        print(f"Data path: {data_path}")
        
        try:
            train_dataset = load_any_dataset(data_path, dataset_name=dataset_name, is_training=True, input_size=input_size)
            test_dataset = load_any_dataset(data_path, dataset_name=dataset_name, is_training=False, input_size=input_size)
            
            detected_num_classes = get_num_classes_from_dataset(train_dataset)
            data_info['num_classes'] = detected_num_classes
            data_info['dataset_structure'] = detect_dataset_structure(data_path)
            
            if len(train_dataset) == len(test_dataset) and train_dataset == test_dataset:
                print("No separate test set found, splitting training data...")
                total_size = len(train_dataset)
                test_size = int(0.2 * total_size)
                train_size = total_size - test_size
                train_dataset, test_dataset = random_split(train_dataset, [train_size, test_size])
            
            val_size = int(len(train_dataset) * validation_split)
            train_size = len(train_dataset) - val_size
            
            train_subset, val_subset = random_split(train_dataset, [train_size, val_size])
            
            train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=2)
            val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=2)
            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)
            
            output_path = os.path.join(data_path, 'preprocessed')
            Path(output_path).mkdir(parents=True, exist_ok=True)
            
            torch.save(train_loader, os.path.join(output_path, 'train_loader.pth'))
            torch.save(val_loader, os.path.join(output_path, 'val_loader.pth'))
            torch.save(test_loader, os.path.join(output_path, 'test_loader.pth'))
            
            sample_batch = next(iter(train_loader))
            data_info['input_shape'] = sample_batch[0].shape[1:]
            data_info['preprocessed_path'] = output_path
            data_info['input_size'] = input_size
            data_info['batch_size'] = batch_size
            
            with open(os.path.join(output_path, 'data_info.pkl'), 'wb') as f:
                pickle.dump(data_info, f)
            
            preprocessing_info = {
                "dataset_structure": data_info['dataset_structure'],
                "num_classes": detected_num_classes,
                "input_shape": data_info['input_shape'],
                "train_samples": train_size,
                "val_samples": val_size,
                "test_samples": len(test_dataset)
            }
            
            return {
                "processed_data_path": output_path,
                "preprocessing_info": preprocessing_info
            }
            
        except Exception as e:
            raise Exception(f"Preprocessing failed: {e}")
